{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "from IPython.display import display\n",
    "\n",
    "# read whole year data\n",
    "allFiles = glob.glob(\"data/*.csv\")\n",
    "df = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "df = pd.concat(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_features = ['Marketing Code','Suburb', 'State','Post Code','Classification','Enquired',\n",
    "                     'Loan Amount','loan_reason','property_use']\n",
    "target = 'Enquiry Status';\n",
    "whole_set = selected_features + [target]\n",
    "\n",
    "df = df[whole_set]\n",
    "df = df.replace('On Hold','Rejected')\n",
    "# convert loan amount to number type, and change string to NaN\n",
    "df['Loan Amount'] = pd.to_numeric(df['Loan Amount'],errors='coerce')\n",
    "df = df.dropna(axis=0, how='any')\n",
    "df = df[~df[target].isin(['In Progress','Just Received'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Enquired'] = pd.DatetimeIndex(df['Enquired'])\n",
    "df['Loan Amount'] = df['Loan Amount'].astype(int)\n",
    "df['Post Code'] = df['Post Code'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "# filter years\n",
    "start_date = '2017-01-01' \n",
    "end_date = '2017-12-31'\n",
    "mask = (df['Enquired'] > start_date) & (df['Enquired'] <= end_date)\n",
    "df = df.loc[mask].reset_index(drop=True)\n",
    "\n",
    "# remove Year feature since it is not important (show below random forest)\n",
    "# data_set['Year'] = data_set['Enquired'].dt.year\n",
    "df['Month'] = df['Enquired'].dt.month\n",
    "df['Day'] = df['Enquired'].dt.day\n",
    "df['Hour'] = df['Enquired'].dt.hour\n",
    "df['Weekday'] = df['Enquired'].dt.weekday_name\n",
    "\n",
    "df = df.loc[:,df.columns != 'Enquiried']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of data types: \n",
      "Marketing Code            object\n",
      "Suburb                    object\n",
      "State                     object\n",
      "Post Code                  int64\n",
      "Classification            object\n",
      "Enquired          datetime64[ns]\n",
      "Loan Amount                int64\n",
      "loan_reason               object\n",
      "property_use              object\n",
      "Enquiry Status            object\n",
      "Month                      int64\n",
      "Day                        int64\n",
      "Hour                       int64\n",
      "Weekday                   object\n",
      "dtype: object\n",
      "selected encoded_columns: \n",
      "['Marketing Code', 'Suburb', 'State', 'Classification', 'loan_reason', 'property_use', 'Enquiry Status', 'Weekday']\n"
     ]
    }
   ],
   "source": [
    "print(\"List of data types: \\n{}\".format(df.dtypes))\n",
    "\n",
    "encoded_columns = list(df.select_dtypes(include=['category','object']))\n",
    "\n",
    "print(\"selected encoded_columns: \\n{}\".format(encoded_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = le.fit_transform(output[col].astype(str))\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = le.fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mce = MultiColumnLabelEncoder(columns = encoded_columns);\n",
    "df = mce.fit_transform(df)\n",
    "\n",
    "X = df[df.keys()]\n",
    "X = X.drop(['Enquiry Status'],1)\n",
    "X = X.drop(['Enquired'],1)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                     test_size=0.3,\n",
    "                     random_state=0,\n",
    "                     stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mluo/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/mluo/anaconda3/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_svm = make_pipeline(StandardScaler(),PCA(n_components=2),LogisticRegression(random_state=1))\n",
    "\n",
    "pipe_svm.fit(X_train, y_train)\n",
    "y_svm_pred = pipe_svm.predict(X_test)\n",
    "print('Test Accuracy: %.3f' % pipe_svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe_rfc = make_pipeline(StandardScaler(),PCA(n_components=2),RandomForestClassifier(random_state=1))\n",
    "\n",
    "pipe_rfc.fit(X_train, y_train)\n",
    "y_rfc_pred = pipe_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "cross_validation: 0.85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      1346\n",
      "          1       0.85      1.00      0.92      7916\n",
      "\n",
      "avg / total       0.73      0.85      0.79      9262\n",
      "\n",
      "RandomForest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mluo/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_validation: 0.81\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.32      0.39      1346\n",
      "          1       0.89      0.95      0.92      7916\n",
      "\n",
      "avg / total       0.84      0.86      0.84      9262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(\"LogisticRegression\")\n",
    "scores = cross_validation.cross_val_score(pipe_svm, X, y, cv=3)\n",
    "print(\"cross_validation: {:.2f}\".format(np.mean(scores, axis=0)))\n",
    "print(classification_report(y_test, y_svm_pred))\n",
    "\n",
    "\n",
    "print(\"RandomForest\")\n",
    "scores = cross_validation.cross_val_score(pipe_rfc, X, y, cv=3)\n",
    "print(\"cross_validation: {:.2f}\".format(np.mean(scores, axis=0)))\n",
    "print(classification_report(y_test, y_rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['app/models/svm_model_columns.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(pipe_svm, 'app/models/svmpipeline.pkl')\n",
    "\n",
    "model_columns = list(X.columns)\n",
    "joblib.dump(model_columns, 'app/models/svm_model_columns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
