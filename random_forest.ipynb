{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import glob\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "mpl.rcParams['savefig.dpi'] = 128\n",
    "mpl.rcParams['figure.dpi'] = 128\n",
    "# Plot size to 14\" x 7\"\n",
    "mpl.rc('figure', figsize = (14, 7))\n",
    "# Font size to 14\n",
    "mpl.rc('font', size = 14)\n",
    "# Do not display top and right frame lines\n",
    "mpl.rc('axes.spines', top = False, right = False)\n",
    "# Remove grid lines\n",
    "mpl.rc('axes', grid = False)\n",
    "# Set backgound color to white\n",
    "mpl.rc('axes', facecolor = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read whole year data\n",
    "allFiles = glob.glob(\"data/*.csv\")\n",
    "df = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0,encoding=\"utf-8\")\n",
    "    list_.append(df)\n",
    "df = pd.concat(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_cols(df):\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    df.columns = df.columns.str.replace('_', ' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = transform_cols(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['marketing code','suburb', 'state','post code','enquired',\n",
    "                     'loan amount','loan reason','property use']\n",
    "# selected_features = ['marketing code','enquired',\n",
    "#                      'loan amount','loan reason','property use']\n",
    "# selected_features = ['marketing code','enquired','loan amount','property use']\n",
    "target = 'enquiry status';\n",
    "whole_set = selected_features + [target]\n",
    "\n",
    "df = df[whole_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88168, 9)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~df[target].isin(['In Progress','Just Received','On Hold'])]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loan amount'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string to do replacement\n",
    "df['loan amount'] = df['loan amount'].astype(\"str\")\n",
    "df['loan amount'] = df['loan amount'].str.replace(\",\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_columns= ['500001-$1000000',\n",
    "                  '300001-$500000',\n",
    "                  '0-$300000',\n",
    "                  '250000 - 300000',\n",
    "                  '250000-350000',\n",
    "                  '2600 monthly',\n",
    "                  'not_sure',\n",
    "                  '1000,001+',\n",
    "                 '9999-',\n",
    "                  'I50000',\n",
    "                  '1.5 M',\n",
    "                  '1000001+',\n",
    "                  '9999-',\n",
    "                  '80-90k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87716, 9)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~df['loan amount'].isin(invalid_columns)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of null values in:marketing code == 31\n",
      "The number of null values in:suburb == 21423\n",
      "The number of null values in:state == 20150\n",
      "The number of null values in:post code == 6560\n",
      "The number of null values in:enquired == 0\n",
      "The number of null values in:loan amount == 0\n",
      "The number of null values in:loan reason == 19299\n",
      "The number of null values in:property use == 22524\n",
      "The number of null values in:enquiry status == 0\n"
     ]
    }
   ],
   "source": [
    "for _ in df.columns:\n",
    "    print(\"The number of null values in: {} == {}\".format(_, df[_].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57704, 9)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis=0, how='any', inplace=True)\n",
    "# df = df[~df['marketing code'].isnull()]\n",
    "# df = df[~df['post code'].isnull()]\n",
    "# df = df[~df['suburb'].isnull()]\n",
    "# df = df[~df['loan reason'].isnull()]\n",
    "# df = df[~df['property use'].isnull()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of null values in:marketing code == 0\n",
      "The number of null values in:suburb == 0\n",
      "The number of null values in:state == 0\n",
      "The number of null values in:post code == 0\n",
      "The number of null values in:enquired == 0\n",
      "The number of null values in:loan amount == 0\n",
      "The number of null values in:loan reason == 0\n",
      "The number of null values in:property use == 0\n",
      "The number of null values in:enquiry status == 0\n"
     ]
    }
   ],
   "source": [
    "for _ in df.columns:\n",
    "    print(\"The number of null values in:{} == {}\".format(_, df[_].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(df): \n",
    "    df['loan amount'] = df['loan amount'].astype('float')\n",
    "    df['enquired'] = pd.DatetimeIndex(df['enquired'])\n",
    "    df['month'] = df['enquired'].dt.month\n",
    "    df['day'] = df['enquired'].dt.day\n",
    "    df['hour'] = df['enquired'].dt.hour\n",
    "    df['weekday'] = df['enquired'].dt.dayofweek\n",
    "    df['post code'] = df['post code'].astype('int')\n",
    "    \n",
    "    if 'enquired'in df.columns:\n",
    "        df.drop(['enquired'], axis = 1, inplace = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketing code</th>\n",
       "      <th>suburb</th>\n",
       "      <th>state</th>\n",
       "      <th>post code</th>\n",
       "      <th>enquired</th>\n",
       "      <th>loan amount</th>\n",
       "      <th>loan reason</th>\n",
       "      <th>property use</th>\n",
       "      <th>enquiry status</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>A9414</td>\n",
       "      <td>26 McCarthy Drive</td>\n",
       "      <td>Woombye</td>\n",
       "      <td>QLD</td>\n",
       "      <td>2016-05-23 08:21:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Buying Again</td>\n",
       "      <td>Residence</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     marketing code             suburb    state post code            enquired  \\\n",
       "4684          A9414  26 McCarthy Drive  Woombye       QLD 2016-05-23 08:21:28   \n",
       "\n",
       "      loan amount   loan reason property use enquiry status  month  day  hour  \\\n",
       "4684          0.0  Buying Again    Residence       Rejected      5   23     8   \n",
       "\n",
       "      weekday  \n",
       "4684        0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform(df)\n",
    "df[df['post code'] == \"QLD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in df.columns:\n",
    "    print(\"The number of null values in:{} == {}\".format(_, df[_].isnull().sum()))\n",
    "    \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of data frame: {}\".format(df.shape))\n",
    "print(\"Keys of enquiries_dataset: \\n{}\".format(df.keys()))\n",
    "print(\"data ytpes of enquiries_dataset: \\n{}\".format(df.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[df['enquiry status'] == 'Rejected']\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[df['enquiry status'] == 'Accepted']\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = df[df['enquiry status'] == 'Rejected']\n",
    "df_minority = df[df['enquiry status'] == 'Accepted']\n",
    "\n",
    "\n",
    "# Upsample minority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,     # sample with replacement\n",
    "                                 n_samples=11279,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# Display new class counts\n",
    "df_downsampled['enquiry status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of new data frame: {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"data ytpes of enquiries_dataset: \\n{}\".format(df.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col].astype(str))\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.iloc[:number_of_rows]\n",
    "X = df[df.keys()]\n",
    "X = df.loc[:,df.columns != target]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = df[target]\n",
    "y = le.fit_transform(y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_column = X.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = MultiColumnLabelEncoder(columns = category_column.columns).fit_transform(X)\n",
    "X = pd.get_dummies(X, columns=category_column.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                     test_size=0.3,\n",
    "                     random_state=0,\n",
    "                     stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                        PCA(),\n",
    "                        LogisticRegression(penalty='l2'))\n",
    "\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "lr_label = pipe_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "scores = cross_validation.cross_val_score(pipe_lr, X, y, cv=5)\n",
    "print(\"Logist Regression cross_validation: {:.2f}\".format(np.mean(scores, axis=0)))\n",
    "\n",
    "print(\"Report\\n\")\n",
    "print(classification_report(y_test, lr_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_y_2 = pipe_lr.predict_proba(X)\n",
    "prob_y_2 = [p[1] for p in prob_y_2]\n",
    "print( roc_auc_score(y, prob_y_2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_rf = make_pipeline(StandardScaler(),\n",
    "                        PCA(),\n",
    "                        RandomForestClassifier(n_estimators=500,random_state=1))\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "rf_label = pipe_rf.predict(X_test)\n",
    "# print('Test Accuracy: %.3f' % pipe_rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_rf,\n",
    "#                                                         X=X_train,y=y_train,train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "#                                                         cv=10,n_jobs=1)\n",
    "# train_mean = np.mean(train_scores,axis=1)\n",
    "# train_std = np.std(train_scores, axis=1)      \n",
    "# test_mean = np.mean(test_scores, axis=1)\n",
    "# test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "\n",
    "# plt.plot(train_sizes, train_mean,color='blue', marker='o',markersize=5,label='training accuracy')\n",
    "# plt.fill_between(train_sizes,train_mean + train_std,train_mean - train_std,alpha=0.15, color='blue')\n",
    "# plt.plot(train_sizes, test_mean,color='green', linestyle='--',marker='s', markersize=5,label='validation accuracy')\n",
    "# plt.fill_between(train_sizes,test_mean + test_std,test_mean - test_std,alpha=0.15, color='green')\n",
    "# plt.grid()\n",
    "# plt.xlabel('Number of training samples')\n",
    "# plt.ylabel('Accuracy')               \n",
    "# plt.legend(loc='lower right')\n",
    "# plt.ylim([0.8, 1.0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "scores = cross_validation.cross_val_score(pipe_rf, X, y, cv=5)\n",
    "print(\"Random forest cross_validation: {:.2f}\".format(np.mean(scores, axis=0)))\n",
    "\n",
    "print(\"Random forest\")\n",
    "print(classification_report(y_test, rf_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_y_2 = pipe_rf.predict_proba(X)\n",
    "prob_y_2 = [p[1] for p in prob_y_2]\n",
    "print( roc_auc_score(y, prob_y_2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.unique( rf_label ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# from sklearn import metrics\n",
    "\n",
    "# # rescale data\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# rfc = RandomForestClassifier(n_estimators=500,random_state=1)\n",
    "# rfc.fit(X_train_scaled, y_train)\n",
    "# pred_forest = rfc.predict(X_test)\n",
    "\n",
    "# print(\"Test score: {:.2f}\".format(rfc.score(X_test_scaled, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_sizes, train_scores, test_scores = learning_curve(estimator=rfc,\n",
    "#                                                         X=X_train,y=y_train,train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "#                                                         cv=10,n_jobs=1)\n",
    "# train_mean = np.mean(train_scores,axis=1)\n",
    "# train_std = np.std(train_scores, axis=1)      \n",
    "# test_mean = np.mean(test_scores, axis=1)\n",
    "# test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "\n",
    "# plt.plot(train_sizes, train_mean,color='blue', marker='o',markersize=5,label='training accuracy')\n",
    "# plt.fill_between(train_sizes,train_mean + train_std,train_mean - train_std,alpha=0.15, color='blue')\n",
    "# plt.plot(train_sizes, test_mean,color='green', linestyle='--',marker='s', markersize=5,label='validation accuracy')\n",
    "# plt.fill_between(train_sizes,test_mean + test_std,test_mean - test_std,alpha=0.15, color='green')\n",
    "# plt.grid()\n",
    "# plt.xlabel('Number of training samples')\n",
    "# plt.ylabel('Accuracy')               \n",
    "# plt.legend(loc='lower right')\n",
    "# plt.ylim([0.8, 1.0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feat_labels = X.columns[0:]\n",
    "# importances = rfc.feature_importances_\n",
    "# importances = [x for x in j if x >= 5]\n",
    "\n",
    "# # reverse the list\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# for f in range(X_train.shape[1]):\n",
    "#     print(\"%2d) %-*s %f\" % (f + 1, 30,feat_labels[indices[f]],importances[indices[f]]))\n",
    "    \n",
    "# plt.title('Feature Importance')\n",
    "# plt.bar(range(X_train.shape[1]),importances[indices],align='center')\n",
    "# plt.xticks(range(X_train.shape[1]),feat_labels[indices], rotation=90)\n",
    "# plt.xlim([-1, X_train.shape[1]])\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import os\n",
    "\n",
    "# dest = os.path.join('movieclassifier', 'pkl_objects')\n",
    "# if not os.path.exists(dest):\n",
    "#     os.makedirs(dest)\n",
    "\n",
    "# pickle.dump(stop,open(os.path.join(dest, 'stopwords.pkl'),'wb'),protocol=4)\n",
    "# pickle.dump(clf,\n",
    "            \n",
    "# from sklearn.externals import joblib\n",
    "# joblib.dump(pipe_rf, 'app/models/classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(pipe_rf, 'app/models/classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_columns = list(X.columns)\n",
    "joblib.dump(model_columns, 'app/models/model_columns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load('app/models/classifier.pkl')\n",
    "model_columns = joblib.load('app/models/model_columns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "my_json_string = json.dumps({\n",
    "    \"marketing_code\": \"P0001\",\n",
    "    \"loan amount\": \"260000\",\n",
    "    \"enquired\":'27/10/13 21:58',\n",
    "    \"property_use\": \"Residence\"\n",
    "})\n",
    "my_json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_json(my_json_string, orient='index')\n",
    "# data = pd.read_json(my_json_string, typ='series',orient='index')\n",
    "# data = pd.DataFrame(data=data)\n",
    "data = json.loads(my_json_string)\n",
    "data = pd.DataFrame(data,index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_cols(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanFeatures(data) :\n",
    "    for col in model_columns: \n",
    "        if col not in data.columns:\n",
    "            data[col] = 0\n",
    "        else:\n",
    "            print(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanFeatures(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pipe_rf.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"posibility is: {}\".format(np.max(pipe_rf.predict_proba(data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
