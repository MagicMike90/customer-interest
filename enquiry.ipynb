{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib as mpl\n",
    "import warnings\n",
    "import glob\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "mpl.rcParams['savefig.dpi'] = 128\n",
    "mpl.rcParams['figure.dpi'] = 128\n",
    "# Plot size to 14\" x 7\"\n",
    "mpl.rc('figure', figsize = (14, 7))\n",
    "# Font size to 14\n",
    "mpl.rc('font', size = 14)\n",
    "# Do not display top and right frame lines\n",
    "mpl.rc('axes.spines', top = False, right = False)\n",
    "# Remove grid lines\n",
    "mpl.rc('axes', grid = False)\n",
    "# Set backgound color to white\n",
    "mpl.rc('axes', facecolor = 'white')\n",
    "\n",
    "\n",
    "# df_fleats = pd.read_csv('data/marketing-breakdown-detailed.csv')\n",
    "# df_fleats = df_fleats.append(pd.read_csv('data/marketing-breakdown-detailed (2).csv'))\n",
    "# df_fleats = df_fleats.append(pd.read_csv('data/marketing-breakdown-detailed (3).csv'))\n",
    "# df_fleats = df_fleats.append(pd.read_csv('data/marketing-breakdown-detailed (4).csv'))\n",
    "# read whole year data\n",
    "allFiles = glob.glob(\"data/*.csv\")\n",
    "df_fleats = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0,parse_dates=False)\n",
    "    list_.append(df)\n",
    "df_fleats = pd.concat(list_)\n",
    "\n",
    "\n",
    "selected_features = ['Marketing Code','Suburb', 'State','Post Code','Classification','Enquired',\n",
    "                     'Loan Amount','loan_reason','property_use']\n",
    "target = 'Enquiry Status';\n",
    "whole_set = selected_features + [target]\n",
    "\n",
    "data_set = df_fleats[whole_set]\n",
    "data_set = data_set.replace('On Hold','Rejected')\n",
    "# convert loan amount to number type, and change string to NaN\n",
    "data_set['Loan Amount'] = pd.to_numeric(data_set['Loan Amount'],errors='coerce')\n",
    "data_set = data_set.dropna(axis=0, how='any')\n",
    "\n",
    "data_set['Loan Amount'] = data_set['Loan Amount'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "data_set['Enquired'] = pd.DatetimeIndex(data_set['Enquired'])\n",
    "# df['Enquired'] = temp\n",
    "# df['Enquired Date'] = pd.to_datetime(temp.date)\n",
    "# df['Enquired Time'] = temp.time\n",
    "# data_set = data_set.drop(['Enquired'],1)\n",
    "\n",
    "# filter years\n",
    "start_date = '2017-01-01' \n",
    "end_date = '2017-12-31'\n",
    "mask = (data_set['Enquired'] > start_date) & (data_set['Enquired'] <= end_date)\n",
    "data_set = data_set.loc[mask].reset_index(drop=True)\n",
    "data_set['Year'] = data_set['Enquired'].dt.year\n",
    "data_set['Month'] = data_set['Enquired'].dt.month\n",
    "data_set['Day'] = data_set['Enquired'].dt.day\n",
    "data_set['Hour'] = data_set['Enquired'].dt.hour\n",
    "data_set['Weekday'] = data_set['Enquired'].dt.weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "# generate some random data (approximately over 5 years)\n",
    "data_1 = data_set[['Enquiry Status','Day']]\n",
    "data_2 = data_set[['Enquiry Status','Hour']]\n",
    "\n",
    "plot_date = data_1.groupby(['Day', 'Enquiry Status']).size().reset_index(name=\"counts\")\n",
    "plot_date = plot_date.loc[plot_date['Enquiry Status'] == 'Accepted']\n",
    "\n",
    "# plot_time = data_2.groupby(['Hour', 'Enquiry Status']).size().reset_index(name=\"counts\")\n",
    "# plot_time = plot_time.loc[plot_time['Enquiry Status'] == 'Accepted']\n",
    "\n",
    "\n",
    "plt.plot_date(x=plot_time['Hour'], y=plot_time['counts'],fmt=\"r-\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "plt_accepted = data_set.loc[data_set['Enquiry Status'] == 'Accepted']\n",
    "\n",
    "# get and sort acceptances by day\n",
    "count_day_accepted = plt_accepted.groupby(['day_of_week']).size().reset_index(name=\"counts\")\n",
    "weekdays = list(calendar.day_name)\n",
    "mapping = {day: i for i, day in enumerate(weekdays)}\n",
    "key = count_day_accepted['day_of_week'].map(mapping)\n",
    "count_day_accepted = count_day_accepted.iloc[key.argsort()].reset_index(drop=True)\n",
    "\n",
    "\n",
    "plt_rejected = data_set.loc[data_set['Enquiry Status'] == 'Rejected']\n",
    "\n",
    "count_day_rejected = plt_rejected.groupby(['day_of_week']).size().reset_index(name=\"counts\")\n",
    "weekdays = list(calendar.day_name)\n",
    "mapping = {day: i for i, day in enumerate(weekdays)}\n",
    "key = count_day_rejected['day_of_week'].map(mapping)\n",
    "count_day_rejected = count_day_rejected.iloc[key.argsort()].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "plt_X1 = plt_accepted[['Loan Amount','day_of_week']]\n",
    "plt_y1 = plt_accepted[['Enquiry Status']]\n",
    "\n",
    "# ax = count_day.plot()\n",
    "# ax.set_xlabel(\"Day\")\n",
    "# plt.plot_date(x=count_day['day_of_week'], y=count_day['counts'],fmt=\"r-\")\n",
    "# plt.plot_date(x=count_date['Enquired Date'], y=count_date['counts'],fmt=\"r-\")\n",
    "\n",
    "# plt.plot(count_day_accepted['day_of_week'], count_day_accepted['counts'])\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n",
    "\n",
    "# print(count_day_accepted['day_of_week'].shape[0])\n",
    "plt.title('Accpeted counts by day')\n",
    "plt.bar(range(count_day_accepted['day_of_week'].shape[0]), count_day_accepted['counts'])\n",
    "plt.xticks(range(count_day_accepted['day_of_week'].shape[0]),count_day_accepted['day_of_week'].values, rotation=45)\n",
    "plt.show()\n",
    "\n",
    "plt.title('Rejected counts by day')\n",
    "plt.bar(range(count_day_rejected['day_of_week'].shape[0]), count_day_rejected['counts'])\n",
    "plt.xticks(range(count_day_rejected['day_of_week'].shape[0]),count_day_rejected['day_of_week'].values, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self, columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self, X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = le.fit_transform(output[col])\n",
    "#                 output[col] = OneHotEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname, col in output.iteritems():\n",
    "                output[colname] = le.fit_transform(col)\n",
    "#                 output[colname] = OneHotEncoder().fit_transform(col)\n",
    "        return output\n",
    "       \n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_df = data_set.loc[:, data_set.columns != 'Loan Amount']\n",
    "# MultiColumnLabelEncoder(columns = encoded_df.keys()).fit_transform(data_set)\n",
    "# X = MultiColumnLabelEncoder(columns = encode_df.keys()).fit_transform(X)\n",
    "# y = le.fit_transform(y)\n",
    "data_set = MultiColumnLabelEncoder(columns = encoded_df.keys()).fit_transform(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = data_set[['Marketing Code','App Source', 'Web Source', 'Classification','Enquired Date',]]\n",
    "X = data_set[data_set.keys()]\n",
    "X = X.drop(['Enquiry Status'],1)\n",
    "X = X.drop(['Enquired'],1)\n",
    "y = data_set[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Keys of enquiries_dataset: \\n{}\".format(X.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Shape of X: {}\".format(X.shape))\n",
    "print(\"Shape of y: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature selection\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "selected_X = model.transform(X)\n",
    "\n",
    "# Get idxs of columns to keep\n",
    "idxs_selected = model.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                     test_size=0.3,\n",
    "                     random_state=0,\n",
    "                     stratify=y)\n",
    "# rescale data\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', C=0.1)\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "print('Training accuracy:', lr.score(X_train_std, y_train))\n",
    "print('Test accuracy:', lr.score(X_test_std, y_test))\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'cyan','magenta', 'yellow', 'black','pink', 'lightgreen', 'lightblue',\n",
    "          'gray', 'indigo', 'orange']\n",
    "\n",
    "weights, params = [], []\n",
    "for c in np.arange(-4., 6.):\n",
    "    lr = LogisticRegression(penalty='l1', C=10. ** c, random_state=0)\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    weights.append(lr.coef_[0])\n",
    "    params.append(10 ** c)\n",
    "    \n",
    "weights = np.array(weights)\n",
    "\n",
    "for column, color in zip(range(weights.shape[1]), colors):\n",
    "    plt.plot(params, weights[:, column],\n",
    "             label=X.columns[column],\n",
    "             color=color)\n",
    "    \n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=3)\n",
    "plt.xlim([10**(-5), 10**5])\n",
    "plt.ylabel('weight coefficient')\n",
    "plt.xlabel('C')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper left')\n",
    "ax.legend(loc='upper center',\n",
    "          bbox_to_anchor=(1.38, 1.03),\n",
    "          ncol=1, fancybox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "kn = KNeighborsClassifier(n_neighbors=7)\n",
    "kn.fit(X_train_std, y_train)\n",
    "pred_kn = kn.predict(X_test)\n",
    "print(\"Test score: {:.2f}\".format(kn.score(X_test_std, y_test)))\n",
    "\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# try n_neighbors from 1 to 10.\n",
    "neighbors_settings = range(1, 11)\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the model\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # record training set accuracy\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "    \n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "sgd.fit(X_train_std, y_train)\n",
    "pred_sgd = sgd.predict(X_test)\n",
    "print(\"Test score: {:.2f}\".format(sgd.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "rbf_feature = RBFSampler(gamma=1, random_state=1)\n",
    "X_features = rbf_feature.fit_transform(X_train_std)\n",
    "clf = SGDClassifier()  \n",
    "clf.fit(X_train_std, y_train)\n",
    "print(\"Test score: {:.2f}\".format(clf.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svc = svm.SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "pred_svc = svc.predict(X_test)\n",
    "print(\"Test score: {:.2f}\".format(svc.score(X_test, y_test)))\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# N = range(1, 16)\n",
    "# for n in N:\n",
    "#     pca = KernelPCA(n_components=n)\n",
    "#     X_n_kept = pca.fit_transform(X_test_std)\n",
    "#     # Estimate accuracy on the data set with top n components\n",
    "#     classifier = svm.SVC(gamma=0.001)\n",
    "#     score_n_components = cross_val_score(classifier, X_n_kept, y_test).mean()\n",
    "#     print('Score with the data set of top {0} components: {1:.2f}'.format(n, score_n_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=500)\n",
    "rfc.fit(X_train_std, y_train)\n",
    "pred_forest = rfc.predict(X_test)\n",
    "\n",
    "print(\"Test score: {:.2f}\".format(rfc.score(X_test_std, y_test)))\n",
    "\n",
    "scores = cross_val_score(rfc, X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr = lr.fit(X_train_std, y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "\n",
    "# pipe_lr = make_pipeline(PCA(n_components=2),LogisticRegression(random_state=1))\n",
    "\n",
    "# lr = LogisticRegression(penalty='l1', C=0.1, random_state=0)\n",
    "# lr.fit(X_train_std, y_train)\n",
    "# pipe_lr.fit(X_train_std, y_train)\n",
    "# y_pred = pipe_lr.predict(X_test)\n",
    "print(\"Test score: {:.2f}\".format(lr.score(X_test, y_test)))\n",
    "print('Training accuracy:', lr.score(X_train_std, y_train))\n",
    "print('Test accuracy:', lr.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_labels = X.columns[:]\n",
    "importances = rfc.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, feat_labels[indices[f]], importances[indices[f]]))\n",
    "    \n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(X_train.shape[1]),importances,align='center')\n",
    "plt.xticks(range(X_train.shape[1]),feat_labels, rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# count2.plot(logy=True)\n",
    "# plt_X2 = plt_rejected[['Loan Amount','day_of_week']]\n",
    "# plt_y2 = plt_rejected[['Enquiry Status']]\n",
    "# # plt_X = X.sort_values(by=['Loan Amount'])\n",
    "# # plt_X = plt_X['Loan Amount']\n",
    "# # display(plt_X)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.yaxis.set_major_formatter(formatter)\n",
    "# # ax.plot(plt_X, orig_y)\n",
    "# # plt.scatter(plt_X1['day_of_week'], plt_X1['Loan Amount'],color='red', marker='o', label='Accepted')\n",
    "# # plt.scatter(plt_X2['day_of_week'], plt_X2['Loan Amount'], color='blue', marker='x', label='Rejected')\n",
    "# # plt.plot(plt_X1['day_of_week'], plt_y1, label='Accepted')\n",
    "# # plt.plot(plt_X2['day_of_week'],plt_y2, label='Rejected')\n",
    "\n",
    "# plt.xlabel('Day')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.ylabel('Loan Amount')\n",
    "# plt.legend(loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_date_accepted = plt_accepted.groupby(['Enquired Date']).size().reset_index(name=\"counts\")\n",
    "count_date_rejected = plt_rejected.groupby(['Enquired Date']).size().reset_index(name=\"counts\")\n",
    "\n",
    "plt.plot_date(x=count_date_accepted['Enquired Date'], y=count_date_accepted['counts'],fmt=\"r-\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "def millions(x, pos):\n",
    "    'The two args are the value and tick position'\n",
    "    return '$%1.1fM' % (x*1e-6)\n",
    "\n",
    "formatter = FuncFormatter(millions)\n",
    "\n",
    "count_amount_accepted = plt_accepted.groupby(['Loan Amount']).size().reset_index(name=\"counts\")\n",
    "count_amount_rejected = plt_rejected.groupby(['Loan Amount']).size().reset_index(name=\"counts\")\n",
    "\n",
    "# count_amount_accepted.to_csv('test.csv')\n",
    "# display(count_amount_accepted)\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(count_amount_accepted['Loan Amount'], count_amount_accepted['counts'])\n",
    "plt.xticks(rotation=45)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"KNeighborsClassifier:\")\n",
    "# tn, fp, fn, tp = confusion_matrix(y_test, pred_kn).ravel()\n",
    "print(confusion_matrix(y_test, pred_kn))\n",
    "# print (tn, fp, fn, tp)\n",
    "print(\"\\nSGDClassifier:\")\n",
    "print(confusion_matrix(y_test, pred_sgd))\n",
    "print(\"\\nSVC:\")\n",
    "print(confusion_matrix(y_test, pred_svc))\n",
    "print(\"\\nRandomForestClassifier\")\n",
    "print(confusion_matrix(y_test, pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "print(\"f1 score LogisticRegression: {:.2f}\".format(f1_score(y_test, pred_lr, average='weighted')))\n",
    "print(\"f1 score KNeighborsClassifier: {:.2f}\".format(f1_score(y_test, pred_kn, average='weighted')))\n",
    "print(\"f1 score SGDClassifier: {:.2f}\".format(f1_score(y_test, pred_sgd,average='weighted')))\n",
    "print(\"f1 score SVC: {:.2f}\".format(f1_score(y_test, pred_svc,average='weighted')))\n",
    "print(\"f1 score RandomForestClassifier: {:.2f}\".format(f1_score(y_test, pred_forest,average='weighted')))\n",
    "print()\n",
    "print(\"precision score LogisticRegression: {:.2f}\".format(precision_score(y_test, pred_lr, average='weighted')))\n",
    "print(\"precision score KNeighborsClassifier: {:.2f}\".format(precision_score(y_test, pred_kn, average='weighted')))\n",
    "print(\"precision score SGDClassifier: {:.2f}\".format(precision_score(y_test, pred_sgd,average='weighted')))\n",
    "print(\"precision score SVC: {:.2f}\".format(precision_score(y_test, pred_svc,average='weighted')))\n",
    "print(\"precision score RandomForestClassifier: {:.2f}\".format(precision_score(y_test, pred_forest,average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input_x = X.iloc[:]\n",
    "# input_x_test = X.iloc[:,idxs_selected]\n",
    "# # input_x = input_x.iloc[0,idxs_selected]\n",
    "\n",
    "# # input_x = input_x.drop('Enquiry Status', 1)\n",
    "\n",
    "# input_x_test = MultiColumnLabelEncoder(columns = input_x_test.keys()).fit_transform(input_x_test)\n",
    "# input_x_test = scaler.fit_transform(input_x_test)\n",
    "\n",
    "# # for row in input_x:\n",
    "# #     result = rfc.predict(row)[0]\n",
    "# #     proba = np.max(rfc.predict_proba(row))    \n",
    "\n",
    "# #     print('reuslt: {}'.format(le.inverse_transform(result)))\n",
    "# #     print('probability: {0}%'.format(proba))\n",
    "# #     print()\n",
    "\n",
    "# # result = rfc.predict(input_x)[0]\n",
    "# # proba = np.max(rfc.predict_proba(input_x))    \n",
    "\n",
    "# # print('reuslt: {}'.format(le.inverse_transform(result)))\n",
    "# # print('probability: {0}%'.format(proba))\n",
    "# result = rfc.predict(input_x_test)\n",
    "# result = le.inverse_transform(result)\n",
    "# proba = rfc.predict_proba(input_x_test)   \n",
    "# proba = [np.max(p) for p in proba]\n",
    "# input_x.to_csv('example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input_x = input_x.assign(predict=result.tolist())\n",
    "# input_x = input_x.assign(possibility=proba)\n",
    "# input_x.head()\n",
    "# input_x.to_csv('result/v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = '[{\"col 1\":\"a\",\"col 2\":\"b\"},{\"col 1\":\"c\",\"col 2\":\"d\"}]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.read_json(a, orient='records')\n",
    "# import json\n",
    "# test_json = json.dumps(a)\n",
    "test = pd.read_json(a, orient='records')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
