{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import glob\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "mpl.rcParams['savefig.dpi'] = 128\n",
    "mpl.rcParams['figure.dpi'] = 128\n",
    "# Plot size to 14\" x 7\"\n",
    "mpl.rc('figure', figsize = (14, 7))\n",
    "# Font size to 14\n",
    "mpl.rc('font', size = 14)\n",
    "# Do not display top and right frame lines\n",
    "mpl.rc('axes.spines', top = False, right = False)\n",
    "# Remove grid lines\n",
    "mpl.rc('axes', grid = False)\n",
    "# Set backgound color to white\n",
    "mpl.rc('axes', facecolor = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148615, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"2009-2017_small.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rejected    36654\n",
       "Accepted    36654\n",
       "Name: enquiry status, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = df[df['enquiry status'] == 'Rejected']\n",
    "df_minority = df[df['enquiry status'] == 'Accepted']\n",
    "\n",
    "\n",
    "# Upsample minority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,     # sample with replacement\n",
    "                                 n_samples=36654,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# Display new class counts\n",
    "df_downsampled['enquiry status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiColumnLabelEncoder(LabelEncoder):\n",
    "    \"\"\"\n",
    "    Wraps sklearn LabelEncoder functionality for use on multiple columns of a\n",
    "    pandas dataframe.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, dframe):\n",
    "        \"\"\"\n",
    "        Fit label encoder to pandas columns.\n",
    "\n",
    "        Access individual column classes via indexig `self.all_classes_`\n",
    "\n",
    "        Access individual column encoders via indexing\n",
    "        `self.all_encoders_`\n",
    "        \"\"\"\n",
    "        # if columns are provided, iterate through and get `classes_`\n",
    "        if self.columns is not None:\n",
    "            # ndarray to hold LabelEncoder().classes_ for each\n",
    "            # column; should match the shape of specified `columns`\n",
    "            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n",
    "                                           dtype=object)\n",
    "            self.all_encoders_ = np.ndarray(shape=self.columns.shape,\n",
    "                                            dtype=object)\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                # fit LabelEncoder to get `classes_` for the column\n",
    "                le = LabelEncoder()\n",
    "                le.fit(dframe.loc[:, column].values)\n",
    "                # append the `classes_` to our ndarray container\n",
    "                self.all_classes_[idx] = (column,\n",
    "                                          np.array(le.classes_.tolist(),\n",
    "                                                  dtype=object))\n",
    "                # append this column's encoder\n",
    "                self.all_encoders_[idx] = le\n",
    "        else:\n",
    "            # no columns specified; assume all are to be encoded\n",
    "            self.columns = dframe.iloc[:, :].columns\n",
    "            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n",
    "                                           dtype=object)\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                le = LabelEncoder()\n",
    "                le.fit(dframe.loc[:, column].values)\n",
    "                self.all_classes_[idx] = (column,\n",
    "                                          np.array(le.classes_.tolist(),\n",
    "                                                  dtype=object))\n",
    "                self.all_encoders_[idx] = le\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, dframe):\n",
    "        \"\"\"\n",
    "        Fit label encoder and return encoded labels.\n",
    "\n",
    "        Access individual column classes via indexing\n",
    "        `self.all_classes_`\n",
    "\n",
    "        Access individual column encoders via indexing\n",
    "        `self.all_encoders_`\n",
    "\n",
    "        Access individual column encoded labels via indexing\n",
    "        `self.all_labels_`\n",
    "        \"\"\"\n",
    "        # if columns are provided, iterate through and get `classes_`\n",
    "        if self.columns is not None:\n",
    "            # ndarray to hold LabelEncoder().classes_ for each\n",
    "            # column; should match the shape of specified `columns`\n",
    "            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n",
    "                                           dtype=object)\n",
    "            self.all_encoders_ = np.ndarray(shape=self.columns.shape,\n",
    "                                            dtype=object)\n",
    "            self.all_labels_ = np.ndarray(shape=self.columns.shape,\n",
    "                                          dtype=object)\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                # instantiate LabelEncoder\n",
    "                le = LabelEncoder()\n",
    "                # fit and transform labels in the column\n",
    "                dframe.loc[:, column] =\\\n",
    "                    le.fit_transform(dframe.loc[:, column].values)\n",
    "                # append the `classes_` to our ndarray container\n",
    "                self.all_classes_[idx] = (column,\n",
    "                                          np.array(le.classes_.tolist(),\n",
    "                                                  dtype=object))\n",
    "                self.all_encoders_[idx] = le\n",
    "                self.all_labels_[idx] = le\n",
    "        else:\n",
    "            # no columns specified; assume all are to be encoded\n",
    "            self.columns = dframe.iloc[:, :].columns\n",
    "            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n",
    "                                           dtype=object)\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                le = LabelEncoder()\n",
    "                dframe.loc[:, column] = le.fit_transform(\n",
    "                        dframe.loc[:, column].values)\n",
    "                self.all_classes_[idx] = (column,\n",
    "                                          np.array(le.classes_.tolist(),\n",
    "                                                  dtype=object))\n",
    "                self.all_encoders_[idx] = le\n",
    "        return dframe\n",
    "\n",
    "    def transform(self, dframe):\n",
    "        \"\"\"\n",
    "        Transform labels to normalized encoding.\n",
    "        \"\"\"\n",
    "        if self.columns is not None:\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                dframe.loc[:, column] = self.all_encoders_[\n",
    "                    idx].transform(dframe.loc[:, column].values)\n",
    "        else:\n",
    "            self.columns = dframe.iloc[:, :].columns\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                dframe.loc[:, column] = self.all_encoders_[idx]\\\n",
    "                    .transform(dframe.loc[:, column].values)\n",
    "        return dframe\n",
    "\n",
    "    def inverse_transform(self, dframe):\n",
    "        \"\"\"\n",
    "        Transform labels back to original encoding.\n",
    "        \"\"\"\n",
    "        if self.columns is not None:\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                dframe.loc[:, column] = self.all_encoders_[idx]\\\n",
    "                    .inverse_transform(dframe.loc[:, column].values)\n",
    "        else:\n",
    "            self.columns = dframe.iloc[:, :].columns\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                dframe.loc[:, column] = self.all_encoders_[idx]\\\n",
    "                    .inverse_transform(dframe.loc[:, column].values)\n",
    "        return dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Accepted', 'Rejected'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "target = 'enquiry status';\n",
    "# df = df.iloc[:number_of_rows]\n",
    "X = df[df.keys()]\n",
    "X = df.loc[:,df.columns != target]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = df[target]\n",
    "y = le.fit_transform(y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# category_column = X.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcle = MultiColumnLabelEncoder(columns=category_column.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = mcle.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73308, 49)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run LDA\n",
    "lda = LinearDiscriminantAnalysis(n_components=None)\n",
    "features_lda = lda.fit(X, y)\n",
    "\n",
    "# Create array of explained variance ratios\n",
    "lda_var_ratios = lda.explained_variance_ratio_\n",
    "\n",
    "# Create function\n",
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "    # Set initial variance explained so far\n",
    "    total_variance = 0.0\n",
    "\n",
    "    # Set initial number of features\n",
    "    n_components = 0\n",
    "\n",
    "    # For the explained variance of each feature:\n",
    "    for explained_variance in var_ratio:\n",
    "\n",
    "        # Add the explained variance to the total\n",
    "        total_variance += explained_variance\n",
    "\n",
    "        # Add one to the number of components\n",
    "        n_components += 1\n",
    "\n",
    "        # If we reach our goal level of explained variance\n",
    "        if total_variance >= goal_var:\n",
    "            # End the loop\n",
    "            break\n",
    "\n",
    "    # Return the number of components\n",
    "    return n_components\n",
    "\n",
    "# Run function\n",
    "select_n_components(lda_var_ratios, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                     test_size=0.4,\n",
    "                     random_state=0,\n",
    "                     stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_rf = make_pipeline(StandardScaler(),\n",
    "                        RandomForestClassifier(n_estimators=1000,random_state=1))\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "rf_label = pipe_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mluo/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest cross_validation: 0.45\n",
      "Random forest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.52      0.52     14662\n",
      "          1       0.52      0.52      0.52     14662\n",
      "\n",
      "avg / total       0.52      0.52      0.52     29324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import cross_validation\n",
    "\n",
    "scores = cross_validation.cross_val_score(pipe_rf, X, y, cv=5)\n",
    "print(\"Random forest cross_validation: {:.2f}\".format(np.mean(scores, axis=0)))\n",
    "\n",
    "print(\"Random forest\")\n",
    "print(classification_report(y_test, rf_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87315511425\n"
     ]
    }
   ],
   "source": [
    "prob_y_2 = pipe_rf.predict_proba(X)\n",
    "prob_y_2 = [p[1] for p in prob_y_2]\n",
    "print( roc_auc_score(y, prob_y_2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) day                            0.028814\n",
      " 2) classification_Real Estate View 0.027619\n",
      " 3) classification_Phone           0.026279\n",
      " 4) classification_Affiliate       0.026078\n",
      " 5) month                          0.025718\n",
      " 6) classification_Portal Campaigns 0.025557\n",
      " 7) classification_Direct          0.025081\n",
      " 8) hour                           0.024962\n",
      " 9) classification_Australian Chinese Daily 0.024876\n",
      "10) classification_Money Manager   0.024751\n",
      "11) classification_Domain Campaigns 0.024542\n",
      "12) classification_Domain          0.024454\n",
      "13) classification_Refinancing Direct 0.024437\n",
      "14) weekday                        0.024371\n",
      "15) classification_Domain Bonus Display 0.024315\n",
      "16) classification_Home Sales      0.024193\n",
      "17) classification_Refinancing AdWords 0.024175\n",
      "18) classification_Partners        0.024167\n",
      "19) classification_Domain Competitions 0.024006\n",
      "20) classification_Domain Campaigns CPA 0.023993\n",
      "21) classification_Manila          0.023773\n",
      "22) classification_Referrer        0.023681\n",
      "23) classification_All Homes       0.023616\n",
      "24) classification_Home Hound      0.023466\n",
      "25) classification_None            0.023444\n",
      "26) classification_On The House    0.023391\n",
      "27) classification_Coregistration  0.023361\n",
      "28) classification_REA             0.023342\n",
      "29) classification_Domain Campaigns CPL 0.023036\n",
      "30) classification_Folio           0.022997\n",
      "31) classification_External Email  0.022688\n",
      "32) classification_Bloom           0.022638\n",
      "33) classification_Club FS         0.022516\n",
      "34) classification_Omnilead        0.022406\n",
      "35) classification_Portals         0.022297\n",
      "36) classification_Alternative Media 0.022212\n",
      "37) classification_First Home Buyers 0.021923\n",
      "38) classification_Finder          0.021910\n",
      "39) classification_Google AdWords  0.021372\n",
      "40) classification_Domain Internal CBA Program 0.021360\n",
      "41) classification_Dynamic Home Loans 0.021158\n",
      "42) classification_Email eChoice Database 0.021027\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 42 is out of bounds for axis 0 with size 42",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ee7561431b2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%2d) %-*s %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeat_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimportances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 42 is out of bounds for axis 0 with size 42"
     ]
    }
   ],
   "source": [
    "feat_labels = X.columns[0:]\n",
    "importances = pipe_rf.steps[2][1].feature_importances_\n",
    "\n",
    "# reverse the list\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30,feat_labels[indices[f]],importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "my_json_string = json.dumps({\n",
    "    \"marketing_code\": \"OME\",\n",
    "    \"enquired\":\"29/1/15 12:10\",\n",
    "    \"loan amount\": \"530000\",\n",
    "    \"property_use\": \"Residence\",\n",
    "    \"loan_reason\": \"Refinance\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = json.loads(my_json_string)\n",
    "data = pd.DataFrame(data,index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_cols(df):\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    df.columns = df.columns.str.replace('_', ' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_cols(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(df): \n",
    "    df['loan amount'] = df['loan amount'].astype('float')\n",
    "    df['enquired'] = pd.DatetimeIndex(df['enquired'])\n",
    "    df['month'] = df['enquired'].dt.month\n",
    "    df['day'] = df['enquired'].dt.day\n",
    "    df['hour'] = df['enquired'].dt.hour\n",
    "    df['weekday'] = df['enquired'].dt.dayofweek\n",
    "    \n",
    "    if 'post code' in df.columns: \n",
    "        df['post code'] = df['post code'].astype('int')\n",
    "    \n",
    "    if 'enquired'in df.columns:\n",
    "        df.drop(['enquired'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcle.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_label = pipe_rf.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"posibility is: {}\".format(np.max(pipe_rf.predict_proba(data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create logistic regression\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "# Create range of 20 candidate values for C\n",
    "C = np.logspace(0, 4, 20)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C)\n",
    "\n",
    "# Create grid search\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, n_jobs=-1, verbose=0)\n",
    "\n",
    "# Conduct nested cross-validation and outut the average score\n",
    "cross_val_score(gridsearch, features, target).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
