{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import glob\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "mpl.rcParams['savefig.dpi'] = 128\n",
    "mpl.rcParams['figure.dpi'] = 128\n",
    "# Plot size to 14\" x 7\"\n",
    "mpl.rc('figure', figsize = (14, 7))\n",
    "# Font size to 14\n",
    "mpl.rc('font', size = 14)\n",
    "# Do not display top and right frame lines\n",
    "mpl.rc('axes.spines', top = False, right = False)\n",
    "# Remove grid lines\n",
    "mpl.rc('axes', grid = False)\n",
    "# Set backgound color to white\n",
    "mpl.rc('axes', facecolor = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148615, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"2009-2017_small.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rejected    36654\n",
       "Accepted    36654\n",
       "Name: enquiry status, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = df[df['enquiry status'] == 'Rejected']\n",
    "df_minority = df[df['enquiry status'] == 'Accepted']\n",
    "\n",
    "\n",
    "# Upsample minority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,     # sample with replacement\n",
    "                                 n_samples=36654,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# Display new class counts\n",
    "df_downsampled['enquiry status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiColumnLabelEncoder(LabelEncoder):\n",
    "    \"\"\"\n",
    "    Wraps sklearn LabelEncoder functionality for use on multiple columns of a\n",
    "    pandas dataframe.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, dframe):\n",
    "        \"\"\"\n",
    "        Fit label encoder to pandas columns.\n",
    "\n",
    "        Access individual column classes via indexig `self.all_classes_`\n",
    "\n",
    "        Access individual column encoders via indexing\n",
    "        `self.all_encoders_`\n",
    "        \"\"\"\n",
    "        # if columns are provided, iterate through and get `classes_`\n",
    "        if self.columns is not None:\n",
    "            # ndarray to hold LabelEncoder().classes_ for each\n",
    "            # column; should match the shape of specified `columns`\n",
    "            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n",
    "                                           dtype=object)\n",
    "            self.all_encoders_ = np.ndarray(shape=self.columns.shape,\n",
    "                                            dtype=object)\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                # fit LabelEncoder to get `classes_` for the column\n",
    "                le = LabelEncoder()\n",
    "                le.fit(dframe.loc[:, column].values)\n",
    "                # append the `classes_` to our ndarray container\n",
    "                self.all_classes_[idx] = (column,\n",
    "                                          np.array(le.classes_.tolist(),\n",
    "                                                  dtype=object))\n",
    "                # append this column's encoder\n",
    "                self.all_encoders_[idx] = le\n",
    "        else:\n",
    "            # no columns specified; assume all are to be encoded\n",
    "            self.columns = dframe.iloc[:, :].columns\n",
    "            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n",
    "                                           dtype=object)\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                le = LabelEncoder()\n",
    "                le.fit(dframe.loc[:, column].values)\n",
    "                self.all_classes_[idx] = (column,\n",
    "                                          np.array(le.classes_.tolist(),\n",
    "                                                  dtype=object))\n",
    "                self.all_encoders_[idx] = le\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, dframe):\n",
    "        \"\"\"\n",
    "        Fit label encoder and return encoded labels.\n",
    "\n",
    "        Access individual column classes via indexing\n",
    "        `self.all_classes_`\n",
    "\n",
    "        Access individual column encoders via indexing\n",
    "        `self.all_encoders_`\n",
    "\n",
    "        Access individual column encoded labels via indexing\n",
    "        `self.all_labels_`\n",
    "        \"\"\"\n",
    "        # if columns are provided, iterate through and get `classes_`\n",
    "        if self.columns is not None:\n",
    "            # ndarray to hold LabelEncoder().classes_ for each\n",
    "            # column; should match the shape of specified `columns`\n",
    "            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n",
    "                                           dtype=object)\n",
    "            self.all_encoders_ = np.ndarray(shape=self.columns.shape,\n",
    "                                            dtype=object)\n",
    "            self.all_labels_ = np.ndarray(shape=self.columns.shape,\n",
    "                                          dtype=object)\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                # instantiate LabelEncoder\n",
    "                le = LabelEncoder()\n",
    "                # fit and transform labels in the column\n",
    "                dframe.loc[:, column] =\\\n",
    "                    le.fit_transform(dframe.loc[:, column].values)\n",
    "                # append the `classes_` to our ndarray container\n",
    "                self.all_classes_[idx] = (column,\n",
    "                                          np.array(le.classes_.tolist(),\n",
    "                                                  dtype=object))\n",
    "                self.all_encoders_[idx] = le\n",
    "                self.all_labels_[idx] = le\n",
    "        else:\n",
    "            # no columns specified; assume all are to be encoded\n",
    "            self.columns = dframe.iloc[:, :].columns\n",
    "            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n",
    "                                           dtype=object)\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                le = LabelEncoder()\n",
    "                dframe.loc[:, column] = le.fit_transform(\n",
    "                        dframe.loc[:, column].values)\n",
    "                self.all_classes_[idx] = (column,\n",
    "                                          np.array(le.classes_.tolist(),\n",
    "                                                  dtype=object))\n",
    "                self.all_encoders_[idx] = le\n",
    "        return dframe\n",
    "\n",
    "    def transform(self, dframe):\n",
    "        \"\"\"\n",
    "        Transform labels to normalized encoding.\n",
    "        \"\"\"\n",
    "        if self.columns is not None:\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                dframe.loc[:, column] = self.all_encoders_[\n",
    "                    idx].transform(dframe.loc[:, column].values)\n",
    "        else:\n",
    "            self.columns = dframe.iloc[:, :].columns\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                dframe.loc[:, column] = self.all_encoders_[idx]\\\n",
    "                    .transform(dframe.loc[:, column].values)\n",
    "        return dframe\n",
    "\n",
    "    def inverse_transform(self, dframe):\n",
    "        \"\"\"\n",
    "        Transform labels back to original encoding.\n",
    "        \"\"\"\n",
    "        if self.columns is not None:\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                dframe.loc[:, column] = self.all_encoders_[idx]\\\n",
    "                    .inverse_transform(dframe.loc[:, column].values)\n",
    "        else:\n",
    "            self.columns = dframe.iloc[:, :].columns\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                dframe.loc[:, column] = self.all_encoders_[idx]\\\n",
    "                    .inverse_transform(dframe.loc[:, column].values)\n",
    "        return dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Accepted', 'Rejected'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "target = 'enquiry status';\n",
    "# df = df.iloc[:number_of_rows]\n",
    "X = df[df.keys()]\n",
    "X = df.loc[:,df.columns != target]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = df[target]\n",
    "y = le.fit_transform(y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# category_column = X.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcle = MultiColumnLabelEncoder(columns=category_column.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = mcle.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73308, 49)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                     test_size=0.4,\n",
    "                     random_state=0,\n",
    "                     stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_rf = make_pipeline(StandardScaler(),\n",
    "                        PCA(n_components=0.9),\n",
    "                        RandomForestClassifier(n_estimators=1000,random_state=1))\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "rf_label = pipe_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import cross_validation\n",
    "\n",
    "scores = cross_validation.cross_val_score(pipe_rf, X, y, cv=5)\n",
    "print(\"Random forest cross_validation: {:.2f}\".format(np.mean(scores, axis=0)))\n",
    "\n",
    "print(\"Random forest\")\n",
    "print(classification_report(y_test, rf_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_y_2 = pipe_rf.predict_proba(X)\n",
    "prob_y_2 = [p[1] for p in prob_y_2]\n",
    "print( roc_auc_score(y, prob_y_2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_labels = X.columns[0:]\n",
    "importances = pipe_rf.steps[1][1].feature_importances_\n",
    "\n",
    "# reverse the list\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30,feat_labels[indices[f]],importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "my_json_string = json.dumps({\n",
    "    \"marketing_code\": \"OME\",\n",
    "    \"enquired\":\"29/1/15 12:10\",\n",
    "    \"loan amount\": \"530000\",\n",
    "    \"property_use\": \"Residence\",\n",
    "    \"loan_reason\": \"Refinance\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = json.loads(my_json_string)\n",
    "data = pd.DataFrame(data,index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_cols(df):\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    df.columns = df.columns.str.replace('_', ' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_cols(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(df): \n",
    "    df['loan amount'] = df['loan amount'].astype('float')\n",
    "    df['enquired'] = pd.DatetimeIndex(df['enquired'])\n",
    "    df['month'] = df['enquired'].dt.month\n",
    "    df['day'] = df['enquired'].dt.day\n",
    "    df['hour'] = df['enquired'].dt.hour\n",
    "    df['weekday'] = df['enquired'].dt.dayofweek\n",
    "    \n",
    "    if 'post code' in df.columns: \n",
    "        df['post code'] = df['post code'].astype('int')\n",
    "    \n",
    "    if 'enquired'in df.columns:\n",
    "        df.drop(['enquired'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcle.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_label = pipe_rf.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"posibility is: {}\".format(np.max(pipe_rf.predict_proba(data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
