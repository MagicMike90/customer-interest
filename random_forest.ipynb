{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import glob\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "mpl.rcParams['savefig.dpi'] = 128\n",
    "mpl.rcParams['figure.dpi'] = 128\n",
    "# Plot size to 14\" x 7\"\n",
    "mpl.rc('figure', figsize = (14, 7))\n",
    "# Font size to 14\n",
    "mpl.rc('font', size = 14)\n",
    "# Do not display top and right frame lines\n",
    "mpl.rc('axes.spines', top = False, right = False)\n",
    "# Remove grid lines\n",
    "mpl.rc('axes', grid = False)\n",
    "# Set backgound color to white\n",
    "mpl.rc('axes', facecolor = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"2014-2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112780, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data frame: (112780, 12)\n",
      "Keys of enquiries_dataset: \n",
      "Index(['marketing code', 'suburb', 'state', 'post code', 'loan amount',\n",
      "       'loan reason', 'property use', 'enquiry status', 'month', 'day', 'hour',\n",
      "       'weekday'],\n",
      "      dtype='object')\n",
      "data ytpes of enquiries_dataset: \n",
      "marketing code     object\n",
      "suburb             object\n",
      "state              object\n",
      "post code           int64\n",
      "loan amount       float64\n",
      "loan reason        object\n",
      "property use       object\n",
      "enquiry status     object\n",
      "month               int64\n",
      "day                 int64\n",
      "hour                int64\n",
      "weekday             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of data frame: {}\".format(df.shape))\n",
    "print(\"Keys of enquiries_dataset: \\n{}\".format(df.keys()))\n",
    "print(\"data ytpes of enquiries_dataset: \\n{}\".format(df.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87419, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df[df['enquiry status'] == 'Rejected']\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25361, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df[df['enquiry status'] == 'Accepted']\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rejected    25361\n",
       "Accepted    25361\n",
       "Name: enquiry status, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = df[df['enquiry status'] == 'Rejected']\n",
    "df_minority = df[df['enquiry status'] == 'Accepted']\n",
    "\n",
    "\n",
    "# Upsample minority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,     # sample with replacement\n",
    "                                 n_samples=25361,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# Display new class counts\n",
    "df_downsampled['enquiry status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of new data frame: (112780, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of new data frame: {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data ytpes of enquiries_dataset: \n",
      "marketing code     object\n",
      "suburb             object\n",
      "state              object\n",
      "post code           int64\n",
      "loan amount       float64\n",
      "loan reason        object\n",
      "property use       object\n",
      "enquiry status     object\n",
      "month               int64\n",
      "day                 int64\n",
      "hour                int64\n",
      "weekday             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"data ytpes of enquiries_dataset: \\n{}\".format(df.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col].astype(str))\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Accepted', 'Rejected'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'enquiry status';\n",
    "# df = df.iloc[:number_of_rows]\n",
    "X = df[df.keys()]\n",
    "X = df.loc[:,df.columns != target]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = df[target]\n",
    "y = le.fit_transform(y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_column = X.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "\n",
    "# X = MultiColumnLabelEncoder(columns = category_column.columns).fit_transform(X)\n",
    "# X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes = [df.columns.get_loc(c) for c in df.columns if c in category_column.columns ]\n",
    "# indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc = preprocessing.OneHotEncoder(categorical_features=indexes)\n",
    "# test = enc.fit_transform(X)\n",
    "\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = MultiColumnLabelEncoder(columns = category_column.columns).fit_transform(X)\n",
    "X = pd.get_dummies(X, columns=category_column.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112780, 12407)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                     test_size=0.3,\n",
    "                     random_state=0,\n",
    "                     stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# pipe_lr = make_pipeline(StandardScaler(),\n",
    "#                         PCA(),\n",
    "#                         LogisticRegression(penalty='l2'))\n",
    "\n",
    "# pipe_lr.fit(X_train, y_train)\n",
    "# lr_label = pipe_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print( np.unique( lr_label ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import cross_validation\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# scores = cross_validation.cross_val_score(pipe_lr, X, y, cv=5)\n",
    "# print(\"Logist Regression cross_validation: {:.2f}\".format(np.mean(scores, axis=0)))\n",
    "\n",
    "# print(\"Report\\n\")\n",
    "# print(classification_report(y_test, lr_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_y_2 = pipe_lr.predict_proba(X)\n",
    "# prob_y_2 = [p[1] for p in prob_y_2]\n",
    "# print( roc_auc_score(y, prob_y_2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe_lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8540836b31e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlearning_curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_lr,\n\u001b[0m\u001b[1;32m      4\u001b[0m                                                         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                         cv=10,n_jobs=1)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipe_lr' is not defined"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import learning_curve\n",
    "\n",
    "# train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_lr,\n",
    "#                                                         X=X_train,y=y_train,train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "#                                                         cv=10,n_jobs=1)\n",
    "# train_mean = np.mean(train_scores,axis=1)\n",
    "# train_std = np.std(train_scores, axis=1)      \n",
    "# test_mean = np.mean(test_scores, axis=1)\n",
    "# test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "\n",
    "# plt.plot(train_sizes, train_mean,color='blue', marker='o',markersize=5,label='training accuracy')\n",
    "# plt.fill_between(train_sizes,train_mean + train_std,train_mean - train_std,alpha=0.15, color='blue')\n",
    "# plt.plot(train_sizes, test_mean,color='green', linestyle='--',marker='s', markersize=5,label='validation accuracy')\n",
    "# plt.fill_between(train_sizes,test_mean + test_std,test_mean - test_std,alpha=0.15, color='green')\n",
    "# plt.grid()\n",
    "# plt.xlabel('Number of training samples')\n",
    "# plt.ylabel('Accuracy')               \n",
    "# plt.legend(loc='lower right')\n",
    "# plt.ylim([0.8, 1.0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_rf = make_pipeline(StandardScaler(),\n",
    "                        RandomForestClassifier(n_estimators=500,random_state=1))\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "rf_label = pipe_rf.predict(X_test)\n",
    "# print('Test Accuracy: %.3f' % pipe_rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_rf,\n",
    "                                                        X=X_train,y=y_train,train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                                                        cv=10,n_jobs=1)\n",
    "train_mean = np.mean(train_scores,axis=1)\n",
    "train_std = np.std(train_scores, axis=1)      \n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "\n",
    "plt.plot(train_sizes, train_mean,color='blue', marker='o',markersize=5,label='training accuracy')\n",
    "plt.fill_between(train_sizes,train_mean + train_std,train_mean - train_std,alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean,color='green', linestyle='--',marker='s', markersize=5,label='validation accuracy')\n",
    "plt.fill_between(train_sizes,test_mean + test_std,test_mean - test_std,alpha=0.15, color='green')\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')               \n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.8, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "scores = cross_validation.cross_val_score(pipe_rf, X, y, cv=5)\n",
    "print(\"Random forest cross_validation: {:.2f}\".format(np.mean(scores, axis=0)))\n",
    "\n",
    "print(\"Random forest\")\n",
    "print(classification_report(y_test, rf_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_y_2 = pipe_rf.predict_proba(X)\n",
    "prob_y_2 = [p[1] for p in prob_y_2]\n",
    "print( roc_auc_score(y, prob_y_2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.unique( rf_label ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# from sklearn import metrics\n",
    "\n",
    "# # rescale data\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# rfc = RandomForestClassifier(n_estimators=500,random_state=1)\n",
    "# rfc.fit(X_train_scaled, y_train)\n",
    "# pred_forest = rfc.predict(X_test)\n",
    "\n",
    "# print(\"Test score: {:.2f}\".format(rfc.score(X_test_scaled, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_sizes, train_scores, test_scores = learning_curve(estimator=rfc,\n",
    "#                                                         X=X_train,y=y_train,train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "#                                                         cv=10,n_jobs=1)\n",
    "# train_mean = np.mean(train_scores,axis=1)\n",
    "# train_std = np.std(train_scores, axis=1)      \n",
    "# test_mean = np.mean(test_scores, axis=1)\n",
    "# test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "\n",
    "# plt.plot(train_sizes, train_mean,color='blue', marker='o',markersize=5,label='training accuracy')\n",
    "# plt.fill_between(train_sizes,train_mean + train_std,train_mean - train_std,alpha=0.15, color='blue')\n",
    "# plt.plot(train_sizes, test_mean,color='green', linestyle='--',marker='s', markersize=5,label='validation accuracy')\n",
    "# plt.fill_between(train_sizes,test_mean + test_std,test_mean - test_std,alpha=0.15, color='green')\n",
    "# plt.grid()\n",
    "# plt.xlabel('Number of training samples')\n",
    "# plt.ylabel('Accuracy')               \n",
    "# plt.legend(loc='lower right')\n",
    "# plt.ylim([0.8, 1.0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feat_labels = X.columns[0:]\n",
    "# importances = rfc.feature_importances_\n",
    "# importances = [x for x in j if x >= 5]\n",
    "\n",
    "# # reverse the list\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# for f in range(X_train.shape[1]):\n",
    "#     print(\"%2d) %-*s %f\" % (f + 1, 30,feat_labels[indices[f]],importances[indices[f]]))\n",
    "    \n",
    "# plt.title('Feature Importance')\n",
    "# plt.bar(range(X_train.shape[1]),importances[indices],align='center')\n",
    "# plt.xticks(range(X_train.shape[1]),feat_labels[indices], rotation=90)\n",
    "# plt.xlim([-1, X_train.shape[1]])\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import os\n",
    "\n",
    "# dest = os.path.join('movieclassifier', 'pkl_objects')\n",
    "# if not os.path.exists(dest):\n",
    "#     os.makedirs(dest)\n",
    "\n",
    "# pickle.dump(stop,open(os.path.join(dest, 'stopwords.pkl'),'wb'),protocol=4)\n",
    "# pickle.dump(clf,\n",
    "            \n",
    "# from sklearn.externals import joblib\n",
    "# joblib.dump(pipe_rf, 'app/models/classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(pipe_rf, 'app/models/classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_columns = list(X.columns)\n",
    "joblib.dump(model_columns, 'app/models/model_columns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load('app/models/classifier.pkl')\n",
    "model_columns = joblib.load('app/models/model_columns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "my_json_string = json.dumps({\n",
    "    \"marketing_code\": \"P0001\",\n",
    "    \"enquired\":\"27/10/13 21:58\",\n",
    "    \"loan amount\": \"260000\",\n",
    "    \"suburb\": \"THURSDAY ISLAND\",\n",
    "    \"state\": \"QLD\",\n",
    "    \"post code\": \"4875\",\n",
    "    \"property_use\": \"Residence\",\n",
    "    \"loan_reason\": \"Refinance\"\n",
    "})\n",
    "my_json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_json(my_json_string, orient='index')\n",
    "# data = pd.read_json(my_json_string, typ='series',orient='index')\n",
    "# data = pd.DataFrame(data=data)\n",
    "data = json.loads(my_json_string)\n",
    "data = pd.DataFrame(data,index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_cols(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanFeatures(data) :\n",
    "    for col in model_columns: \n",
    "        if col not in data.columns:\n",
    "            data[col] = 0\n",
    "        else:\n",
    "            print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanFeatures(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pipe_lr.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"posibility is: {}\".format(np.max(pipe_lr.predict_proba(data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
