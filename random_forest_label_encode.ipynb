{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import glob\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "mpl.rcParams['savefig.dpi'] = 128\n",
    "mpl.rcParams['figure.dpi'] = 128\n",
    "# Plot size to 14\" x 7\"\n",
    "mpl.rc('figure', figsize = (14, 7))\n",
    "# Font size to 14\n",
    "mpl.rc('font', size = 14)\n",
    "# Do not display top and right frame lines\n",
    "mpl.rc('axes.spines', top = False, right = False)\n",
    "# Remove grid lines\n",
    "mpl.rc('axes', grid = False)\n",
    "# Set backgound color to white\n",
    "mpl.rc('axes', facecolor = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268639, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"2009-2017.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rejected    50269\n",
       "Accepted    50269\n",
       "Name: enquiry status, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = df[df['enquiry status'] == 'Rejected']\n",
    "df_minority = df[df['enquiry status'] == 'Accepted']\n",
    "\n",
    "\n",
    "# Upsample minority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,     # sample with replacement\n",
    "                                 n_samples=50269,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# Display new class counts\n",
    "df_downsampled['enquiry status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiColumnLabelEncoder(LabelEncoder):\n",
    "    \"\"\"\n",
    "    Wraps sklearn LabelEncoder functionality for use on multiple columns of a\n",
    "    pandas dataframe.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, dframe):\n",
    "        \"\"\"\n",
    "        Fit label encoder to pandas columns.\n",
    "\n",
    "        Access individual column classes via indexig `self.all_classes_`\n",
    "\n",
    "        Access individual column encoders via indexing\n",
    "        `self.all_encoders_`\n",
    "        \"\"\"\n",
    "        # if columns are provided, iterate through and get `classes_`\n",
    "        if self.columns is not None:\n",
    "            # ndarray to hold LabelEncoder().classes_ for each\n",
    "            # column; should match the shape of specified `columns`\n",
    "            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n",
    "                                           dtype=object)\n",
    "            self.all_encoders_ = np.ndarray(shape=self.columns.shape,\n",
    "                                            dtype=object)\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                # fit LabelEncoder to get `classes_` for the column\n",
    "                le = LabelEncoder()\n",
    "                le.fit(dframe.loc[:, column].values)\n",
    "                # append the `classes_` to our ndarray container\n",
    "                self.all_classes_[idx] = (column,\n",
    "                                          np.array(le.classes_.tolist(),\n",
    "                                                  dtype=object))\n",
    "                # append this column's encoder\n",
    "                self.all_encoders_[idx] = le\n",
    "        else:\n",
    "            # no columns specified; assume all are to be encoded\n",
    "            self.columns = dframe.iloc[:, :].columns\n",
    "            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n",
    "                                           dtype=object)\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                le = LabelEncoder()\n",
    "                le.fit(dframe.loc[:, column].values)\n",
    "                self.all_classes_[idx] = (column,\n",
    "                                          np.array(le.classes_.tolist(),\n",
    "                                                  dtype=object))\n",
    "                self.all_encoders_[idx] = le\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, dframe):\n",
    "        \"\"\"\n",
    "        Fit label encoder and return encoded labels.\n",
    "\n",
    "        Access individual column classes via indexing\n",
    "        `self.all_classes_`\n",
    "\n",
    "        Access individual column encoders via indexing\n",
    "        `self.all_encoders_`\n",
    "\n",
    "        Access individual column encoded labels via indexing\n",
    "        `self.all_labels_`\n",
    "        \"\"\"\n",
    "        # if columns are provided, iterate through and get `classes_`\n",
    "        if self.columns is not None:\n",
    "            # ndarray to hold LabelEncoder().classes_ for each\n",
    "            # column; should match the shape of specified `columns`\n",
    "            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n",
    "                                           dtype=object)\n",
    "            self.all_encoders_ = np.ndarray(shape=self.columns.shape,\n",
    "                                            dtype=object)\n",
    "            self.all_labels_ = np.ndarray(shape=self.columns.shape,\n",
    "                                          dtype=object)\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                # instantiate LabelEncoder\n",
    "                le = LabelEncoder()\n",
    "                # fit and transform labels in the column\n",
    "                dframe.loc[:, column] =\\\n",
    "                    le.fit_transform(dframe.loc[:, column].values)\n",
    "                # append the `classes_` to our ndarray container\n",
    "                self.all_classes_[idx] = (column,\n",
    "                                          np.array(le.classes_.tolist(),\n",
    "                                                  dtype=object))\n",
    "                self.all_encoders_[idx] = le\n",
    "                self.all_labels_[idx] = le\n",
    "        else:\n",
    "            # no columns specified; assume all are to be encoded\n",
    "            self.columns = dframe.iloc[:, :].columns\n",
    "            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n",
    "                                           dtype=object)\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                le = LabelEncoder()\n",
    "                dframe.loc[:, column] = le.fit_transform(\n",
    "                        dframe.loc[:, column].values)\n",
    "                self.all_classes_[idx] = (column,\n",
    "                                          np.array(le.classes_.tolist(),\n",
    "                                                  dtype=object))\n",
    "                self.all_encoders_[idx] = le\n",
    "        return dframe\n",
    "\n",
    "    def transform(self, dframe):\n",
    "        \"\"\"\n",
    "        Transform labels to normalized encoding.\n",
    "        \"\"\"\n",
    "        if self.columns is not None:\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                dframe.loc[:, column] = self.all_encoders_[\n",
    "                    idx].transform(dframe.loc[:, column].values)\n",
    "        else:\n",
    "            self.columns = dframe.iloc[:, :].columns\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                dframe.loc[:, column] = self.all_encoders_[idx]\\\n",
    "                    .transform(dframe.loc[:, column].values)\n",
    "        return dframe\n",
    "\n",
    "    def inverse_transform(self, dframe):\n",
    "        \"\"\"\n",
    "        Transform labels back to original encoding.\n",
    "        \"\"\"\n",
    "        if self.columns is not None:\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                dframe.loc[:, column] = self.all_encoders_[idx]\\\n",
    "                    .inverse_transform(dframe.loc[:, column].values)\n",
    "        else:\n",
    "            self.columns = dframe.iloc[:, :].columns\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                dframe.loc[:, column] = self.all_encoders_[idx]\\\n",
    "                    .inverse_transform(dframe.loc[:, column].values)\n",
    "        return dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Accepted', 'Rejected'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "target = 'enquiry status';\n",
    "# df = df.iloc[:number_of_rows]\n",
    "X = df[df.keys()]\n",
    "X = df.loc[:,df.columns != target]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = df[target]\n",
    "y = le.fit_transform(y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# category_column = X.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mcle = MultiColumnLabelEncoder(columns=category_column.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = mcle.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100538, 85)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                     test_size=0.4,\n",
    "                     random_state=0,\n",
    "                     stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_rf = make_pipeline(StandardScaler(),\n",
    "                        RandomForestClassifier(n_estimators=1000,random_state=1))\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "rf_label = pipe_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mluo/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest cross_validation: 0.69\n",
      "Random forest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.81      0.77     20108\n",
      "          1       0.79      0.71      0.75     20108\n",
      "\n",
      "avg / total       0.76      0.76      0.76     40216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import cross_validation\n",
    "\n",
    "scores = cross_validation.cross_val_score(pipe_rf, X, y, cv=5)\n",
    "print(\"Random forest cross_validation: {:.2f}\".format(np.mean(scores, axis=0)))\n",
    "\n",
    "print(\"Random forest\")\n",
    "print(classification_report(y_test, rf_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.968181774664\n"
     ]
    }
   ],
   "source": [
    "prob_y_2 = pipe_rf.predict_proba(X)\n",
    "prob_y_2 = [p[1] for p in prob_y_2]\n",
    "print( roc_auc_score(y, prob_y_2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ee7561431b2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfeat_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# reverse the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "feat_labels = X.columns[0:]\n",
    "importances = pipe_rf.steps[2][1].feature_importances_\n",
    "\n",
    "# reverse the list\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30,feat_labels[indices[f]],importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "my_json_string = json.dumps({\n",
    "    \"marketing_code\": \"OME\",\n",
    "    \"enquired\":\"29/1/15 12:10\",\n",
    "    \"loan amount\": \"530000\",\n",
    "    \"property_use\": \"Residence\",\n",
    "    \"loan_reason\": \"Refinance\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = json.loads(my_json_string)\n",
    "data = pd.DataFrame(data,index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_cols(df):\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    df.columns = df.columns.str.replace('_', ' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform_cols(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(df): \n",
    "    df['loan amount'] = df['loan amount'].astype('float')\n",
    "    df['enquired'] = pd.DatetimeIndex(df['enquired'])\n",
    "    df['month'] = df['enquired'].dt.month\n",
    "    df['day'] = df['enquired'].dt.day\n",
    "    df['hour'] = df['enquired'].dt.hour\n",
    "    df['weekday'] = df['enquired'].dt.dayofweek\n",
    "    \n",
    "    if 'post code' in df.columns: \n",
    "        df['post code'] = df['post code'].astype('int')\n",
    "    \n",
    "    if 'enquired'in df.columns:\n",
    "        df.drop(['enquired'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mcle.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_label = pipe_rf.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"posibility is: {}\".format(np.max(pipe_rf.predict_proba(data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create logistic regression\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "# Create range of 20 candidate values for C\n",
    "C = np.logspace(0, 4, 20)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C)\n",
    "\n",
    "# Create grid search\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, n_jobs=-1, verbose=0)\n",
    "\n",
    "# Conduct nested cross-validation and outut the average score\n",
    "cross_val_score(gridsearch, features, target).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
