{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import glob\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "mpl.rcParams['savefig.dpi'] = 128\n",
    "mpl.rcParams['figure.dpi'] = 128\n",
    "# Plot size to 14\" x 7\"\n",
    "mpl.rc('figure', figsize = (14, 7))\n",
    "# Font size to 14\n",
    "mpl.rc('font', size = 14)\n",
    "# Do not display top and right frame lines\n",
    "mpl.rc('axes.spines', top = False, right = False)\n",
    "# Remove grid lines\n",
    "mpl.rc('axes', grid = False)\n",
    "# Set backgound color to white\n",
    "mpl.rc('axes', facecolor = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"2009-2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268639, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data frame: (268639, 9)\n",
      "Keys of enquiries_dataset: \n",
      "Index(['classification', 'loan amount', 'loan reason', 'property use',\n",
      "       'enquiry status', 'month', 'day', 'hour', 'weekday'],\n",
      "      dtype='object')\n",
      "data ytpes of enquiries_dataset: \n",
      "classification    object\n",
      "loan amount        int64\n",
      "loan reason       object\n",
      "property use      object\n",
      "enquiry status    object\n",
      "month              int64\n",
      "day                int64\n",
      "hour               int64\n",
      "weekday            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of data frame: {}\".format(df.shape))\n",
    "print(\"Keys of enquiries_dataset: \\n{}\".format(df.keys()))\n",
    "print(\"data ytpes of enquiries_dataset: \\n{}\".format(df.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218370, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df[df['enquiry status'] == 'Rejected']\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50269, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df[df['enquiry status'] == 'Accepted']\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accepted    50269\n",
       "Rejected    50269\n",
       "Name: enquiry status, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = df[df['enquiry status'] == 'Rejected']\n",
    "df_minority = df[df['enquiry status'] == 'Accepted']\n",
    "\n",
    "\n",
    "# Upsample minority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,     # sample with replacement\n",
    "                                 n_samples=50269,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# Display new class counts\n",
    "df_downsampled['enquiry status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of new data frame: (100538, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of new data frame: {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data ytpes of enquiries_dataset: \n",
      "classification    object\n",
      "loan amount        int64\n",
      "loan reason       object\n",
      "property use      object\n",
      "enquiry status    object\n",
      "month              int64\n",
      "day                int64\n",
      "hour               int64\n",
      "weekday            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"data ytpes of enquiries_dataset: \\n{}\".format(df.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'enquiry status';\n",
    "# df = df.iloc[:number_of_rows]\n",
    "X = df[df.keys()]\n",
    "X = df.loc[:,df.columns != target]\n",
    "\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# X['classification'] = le.fit_transform(X['classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_column = X.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = MultiColumnLabelEncoder(columns = category_column.columns).fit_transform(X)\n",
    "# X = pd.get_dummies(X, columns=category_column.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "class EncodeCategorical(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Encodes a specified list of columns or all columns if None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns  = [col for col in columns]\n",
    "        self.encoders = None\n",
    "\n",
    "    def fit(self, data, target=None):\n",
    "        \"\"\"\n",
    "        Expects a data frame with named columns to encode.\n",
    "        \"\"\"\n",
    "        # Encode all columns if columns is None\n",
    "        if self.columns is None:\n",
    "            self.columns = data.columns\n",
    "\n",
    "\n",
    "        # Fit a label encoder for each column in the data frame\n",
    "        self.encoders = {\n",
    "            column: LabelEncoder().fit(data[column])\n",
    "            for column in self.columns\n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"\n",
    "        Uses the encoders to transform a data frame.\n",
    "        \"\"\"\n",
    "        output = data.copy()\n",
    "        for column, encoder in self.encoders.items():\n",
    "            print(column)\n",
    "            print(data[column])\n",
    "            output[column] = encoder.transform(data[column])\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ec = EncodeCategorical(columns=category_column.columns)\n",
    "# ec.fit(X)\n",
    "# ec.transform(X)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_dict = {col: LabelEncoder() for col in category_column.columns }\n",
    "for col in columns:\n",
    "    X[col] = le_dict[col].fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_mapping = dict(zip(category_column.columns, {}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in category_mapping : \n",
    "    category_mapping[col] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100538, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = df.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                     test_size=0.4,\n",
    "                     random_state=0,\n",
    "                     stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Best Models Using Exhaustive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Create logistic regression\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "# Create range of candidate penalty hyperparameter values\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create range of candidate regularization hyperparamet values\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create dictionary hyperparameter candidates\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# Create grid search\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = gridsearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 1.0\n"
     ]
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating A Baseline Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50096976327829723"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create dummy classifer\n",
    "# dummy = DummyClassifier(strategy='uniform', random_state=1)\n",
    "pipe_dummy = make_pipeline(StandardScaler(),\n",
    "                       DummyClassifier(strategy='uniform', random_state=1))\n",
    "\n",
    "# \"Train\" model\n",
    "pipe_dummy.fit(X_train, y_train)\n",
    "\n",
    "# Get accuracy score\n",
    "pipe_dummy.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_rf = make_pipeline(StandardScaler(),\n",
    "                        RandomForestClassifier(n_estimators=1000,random_state=1))\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "rf_label = pipe_rf.predict(X_test)\n",
    "print('Test Accuracy: %.3f' % pipe_rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import learning_curve\n",
    "\n",
    "# train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_rf,\n",
    "#                                                         X=X_train,y=y_train,train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "#                                                         cv=10,n_jobs=1)\n",
    "# train_mean = np.mean(train_scores,axis=1)\n",
    "# train_std = np.std(train_scores, axis=1)      \n",
    "# test_mean = np.mean(test_scores, axis=1)\n",
    "# test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "\n",
    "# plt.plot(train_sizes, train_mean,color='blue', marker='o',markersize=5,label='training accuracy')\n",
    "# plt.fill_between(train_sizes,train_mean + train_std,train_mean - train_std,alpha=0.15, color='blue')\n",
    "# plt.plot(train_sizes, test_mean,color='green', linestyle='--',marker='s', markersize=5,label='validation accuracy')\n",
    "# plt.fill_between(train_sizes,test_mean + test_std,test_mean - test_std,alpha=0.15, color='green')\n",
    "# plt.grid()\n",
    "# plt.xlabel('Number of training samples')\n",
    "# plt.ylabel('Accuracy')               \n",
    "# plt.legend(loc='lower right')\n",
    "# plt.ylim([0.8, 1.0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mluo/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest cross_validation: 0.68\n",
      "Random forest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.82      0.76     20108\n",
      "          1       0.79      0.67      0.73     20108\n",
      "\n",
      "avg / total       0.75      0.74      0.74     40216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import cross_validation\n",
    "\n",
    "scores = cross_validation.cross_val_score(pipe_rf, X, y, cv=5)\n",
    "print(\"Random forest cross_validation: {:.2f}\".format(np.mean(scores, axis=0)))\n",
    "\n",
    "print(\"Random forest\")\n",
    "print(classification_report(y_test, rf_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.969317593181\n"
     ]
    }
   ],
   "source": [
    "prob_y_2 = pipe_rf.predict_proba(X)\n",
    "prob_y_2 = [p[1] for p in prob_y_2]\n",
    "print( roc_auc_score(y, prob_y_2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print( np.unique( rf_label ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# from sklearn import metrics\n",
    "\n",
    "# # rescale data\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# rfc = RandomForestClassifier(n_estimators=500,random_state=1)\n",
    "# rfc.fit(X_train_scaled, y_train)\n",
    "# pred_forest = rfc.predict(X_test)\n",
    "\n",
    "# print(\"Test score: {:.2f}\".format(rfc.score(X_test_scaled, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_rf,\n",
    "                                                        X=X_train,y=y_train,train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                                                        cv=10,n_jobs=1)\n",
    "train_mean = np.mean(train_scores,axis=1)\n",
    "train_std = np.std(train_scores, axis=1)      \n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "\n",
    "plt.plot(train_sizes, train_mean,color='blue', marker='o',markersize=5,label='training accuracy')\n",
    "plt.fill_between(train_sizes,train_mean + train_std,train_mean - train_std,alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean,color='green', linestyle='--',marker='s', markersize=5,label='validation accuracy')\n",
    "plt.fill_between(train_sizes,test_mean + test_std,test_mean - test_std,alpha=0.15, color='green')\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')               \n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.8, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.savefig('myfig.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifer = pipe_rf.steps[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) loan amount                    0.360307\n",
      " 2) day                            0.140194\n",
      " 3) hour                           0.127441\n",
      " 4) classification                 0.111714\n",
      " 5) month                          0.095004\n",
      " 6) weekday                        0.066136\n",
      " 7) loan reason                    0.065642\n",
      " 8) property use                   0.033563\n"
     ]
    }
   ],
   "source": [
    "feat_labels = X.columns[0:]\n",
    "importances = pipe_rf.steps[1][1].feature_importances_\n",
    "\n",
    "# reverse the list\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30,feat_labels[indices[f]],importances[indices[f]]))\n",
    "    \n",
    "# plt.title('Feature Importance')\n",
    "# plt.bar(range(X_train.shape[1]),importances[indices],align='center')\n",
    "# plt.xticks(range(X_train.shape[1]),feat_labels[indices], rotation=90)\n",
    "# plt.xlim([-1, X_train.shape[1]])\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifer.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import os\n",
    "\n",
    "# dest = os.path.join('movieclassifier', 'pkl_objects')\n",
    "# if not os.path.exists(dest):\n",
    "#     os.makedirs(dest)\n",
    "\n",
    "# pickle.dump(stop,open(os.path.join(dest, 'stopwords.pkl'),'wb'),protocol=4)\n",
    "# pickle.dump(clf,\n",
    "            \n",
    "# from sklearn.externals import joblib\n",
    "# joblib.dump(pipe_rf, 'app/models/classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['app/models/classifier.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(pipe_rf, 'app/models/classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['app/models/model_columns.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_columns = list(X.columns)\n",
    "joblib.dump(model_columns, 'app/models/model_columns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['app/models/encoder.pkl']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ec, 'app/models/encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = joblib.load('app/models/classifier.pkl')\n",
    "model_columns = joblib.load('app/models/model_columns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"classification\": \"REA\", \"marketing_code\": \"IPH\", \"enquired\": \"29/5/15 17:10\", \"loan amount\": \"210000\", \"property_use\": \"Residence\", \"loan_reason\": \"Refinance\"}'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "my_json_string = json.dumps({\n",
    "    \"classification\": \"REA\",\n",
    "    \"marketing_code\": \"IPH\",\n",
    "    \"enquired\":\"29/5/15 17:10\",\n",
    "    \"loan amount\": \"210000\",\n",
    "    \"property_use\": \"Residence\",\n",
    "    \"loan_reason\": \"Refinance\"\n",
    "})\n",
    "my_json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test = pd.read_json(my_json_string, orient='index')\n",
    "# data = pd.read_json(my_json_string, typ='series',orient='index')\n",
    "# data = pd.DataFrame(data=data)\n",
    "data = json.loads(my_json_string)\n",
    "data = pd.DataFrame(data,index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_cols(df):\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    df.columns = df.columns.str.replace('_', ' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>enquired</th>\n",
       "      <th>loan amount</th>\n",
       "      <th>loan reason</th>\n",
       "      <th>marketing code</th>\n",
       "      <th>property use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REA</td>\n",
       "      <td>29/5/15 17:10</td>\n",
       "      <td>210000</td>\n",
       "      <td>Refinance</td>\n",
       "      <td>IPH</td>\n",
       "      <td>Residence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classification       enquired loan amount loan reason marketing code  \\\n",
       "0            REA  29/5/15 17:10      210000   Refinance            IPH   \n",
       "\n",
       "  property use  \n",
       "0    Residence  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_cols(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(df): \n",
    "    df['loan amount'] = df['loan amount'].astype('float')\n",
    "    df['enquired'] = pd.DatetimeIndex(df['enquired'])\n",
    "    df['month'] = df['enquired'].dt.month\n",
    "    df['day'] = df['enquired'].dt.day\n",
    "    df['hour'] = df['enquired'].dt.hour\n",
    "    df['weekday'] = df['enquired'].dt.dayofweek\n",
    "    \n",
    "    if 'post code' in df.columns: \n",
    "        df['post code'] = df['post code'].astype('int')\n",
    "    \n",
    "    if 'enquired'in df.columns:\n",
    "        df.drop(['enquired'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>loan amount</th>\n",
       "      <th>loan reason</th>\n",
       "      <th>marketing code</th>\n",
       "      <th>property use</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REA</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>Refinance</td>\n",
       "      <td>IPH</td>\n",
       "      <td>Residence</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classification  loan amount loan reason marketing code property use  month  \\\n",
       "0            REA     210000.0   Refinance            IPH    Residence      5   \n",
       "\n",
       "   day  hour  weekday  \n",
       "0   29    17        4  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    REA\n",
      "Name: classification, dtype: object\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-0f03e97c59d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-117-866e8d6df390>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersect1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y contains new labels: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36mintersect1d\u001b[0;34m(ar1, ar2, assume_unique)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mar2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "data = ec.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan amount</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>classification_REA</th>\n",
       "      <th>loan reason_Refinance</th>\n",
       "      <th>marketing code_IPH</th>\n",
       "      <th>property use_Residence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan amount  month  day  hour  weekday  classification_REA  \\\n",
       "0     210000.0      5   29    17        4                   1   \n",
       "\n",
       "   loan reason_Refinance  marketing code_IPH  property use_Residence  \n",
       "0                      1                   1                       1  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.get_dummies(data)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanFeatures(data) :\n",
    "    for col in model_columns: \n",
    "        if col not in data.columns:\n",
    "            data[col] = 0\n",
    "\n",
    "#  test any error column in test data\n",
    "for col in data.columns: \n",
    "    if col not in model_columns:\n",
    "        data.drop(col, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanFeatures(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"posibility is: {}\".format(np.max(clf.predict_proba(data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = test.loc[:,test.columns != target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['classification'] = le.transform(data['classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanFeatures(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = []\n",
    "result = clf.predict_proba(data)\n",
    "for row in range(len(result)):\n",
    "    proba.append(np.max(result[row]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = test.loc[:,test.columns != target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"prediction\"] = prediction\n",
    "data[\"re\"] = proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['prediction'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
