{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib as mpl\n",
    "import warnings\n",
    "import glob\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "mpl.rcParams['savefig.dpi'] = 128\n",
    "mpl.rcParams['figure.dpi'] = 128\n",
    "# Plot size to 14\" x 7\"\n",
    "mpl.rc('figure', figsize = (14, 7))\n",
    "# Font size to 14\n",
    "mpl.rc('font', size = 14)\n",
    "# Do not display top and right frame lines\n",
    "mpl.rc('axes.spines', top = False, right = False)\n",
    "# Remove grid lines\n",
    "mpl.rc('axes', grid = False)\n",
    "# Set backgound color to white\n",
    "mpl.rc('axes', facecolor = 'white')\n",
    "\n",
    "\n",
    "# df_fleats = pd.read_csv('data/marketing-breakdown-detailed.csv')\n",
    "# df_fleats = df_fleats.append(pd.read_csv('data/marketing-breakdown-detailed (2).csv'))\n",
    "# df_fleats = df_fleats.append(pd.read_csv('data/marketing-breakdown-detailed (3).csv'))\n",
    "# df_fleats = df_fleats.append(pd.read_csv('data/marketing-breakdown-detailed (4).csv'))\n",
    "# read whole year data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read whole year data\n",
    "allFiles = glob.glob(\"data/2017*.csv\")\n",
    "df = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "df = pd.concat(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(df): \n",
    "    df.columns = map(str.lower, df.columns)   \n",
    "    df.columns = df.columns.str.replace('_', ' ')\n",
    "    \n",
    "    df['enquired'] = pd.DatetimeIndex(df['enquired'])\n",
    "    df['month'] = df['enquired'].dt.month\n",
    "    df['day'] = df['enquired'].dt.day\n",
    "    df['hour'] = df['enquired'].dt.hour\n",
    "    df['weekday'] = df['enquired'].dt.weekday_name\n",
    "\n",
    "#     if(\"enquired\" in df.columns):\n",
    "#         df = df.loc[:,df.columns != 'enquired']\n",
    "        \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_features = ['marketing code','suburb', 'state','post code','enquired',\n",
    "#                      'loan amount','loan reason','property use']\n",
    "selected_features = ['marketing code','enquired','loan amount']\n",
    "\n",
    "# selected_features = ['marketing code','enquired']\n",
    "target = 'enquiry status';\n",
    "whole_set = selected_features + [target]\n",
    "\n",
    "df = df[whole_set]\n",
    "# df = df.replace('On Hold','Rejected')\n",
    "# convert loan amount to number type, and change string to NaN\n",
    "# df['Loan Amount'] = pd.to_numeric(df['Loan Amount'],errors='coerce')\n",
    "# df = df.dropna(axis=0, how='any')\n",
    "# df = df[~df[target].isin(['In Progress','Just Received','On Hold'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of data frame: {}\".format(df.shape))\n",
    "print(\"Keys of enquiries_dataset: \\n{}\".format(df.keys()))\n",
    "print(\"data ytpes of enquiries_dataset: \\n{}\".format(df.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0, how='any')\n",
    "df = df[~df[target].isin(['In Progress','Just Received','On Hold'])]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = df[df.keys()]\n",
    "X = df.loc[:,df.columns != target]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = df[target]\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "df[df.duplicated(keep=False)]\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Enquired'] = pd.DatetimeIndex(df['Enquired'])\n",
    "# df['Loan Amount'] = df['Loan Amount'].astype(int)\n",
    "# df['Post Code'] = df['Post Code'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# from dateutil.parser import parse\n",
    "\n",
    "# # filter years\n",
    "# start_date = '2017-01-01' \n",
    "# end_date = '2017-12-31'\n",
    "# mask = (df['Enquired'] > start_date) & (df['Enquired'] <= end_date)\n",
    "# df = df.loc[mask].reset_index(drop=True)\n",
    "\n",
    "# # remove Year feature since it is not important (show below random forest)\n",
    "# # df['Year'] = df['Enquired'].dt.year\n",
    "# df['Month'] = df['Enquired'].dt.month\n",
    "# df['Day'] = df['Enquired'].dt.day\n",
    "# df['Hour'] = df['Enquired'].dt.hour\n",
    "# df['Weekday'] = df['Enquired'].dt.weekday_name\n",
    "\n",
    "# df = df.loc[:,df.columns != 'Enquired']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(target).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(target).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# import matplotlib.dates as mdates\n",
    "# import matplotlib.mlab as mlab\n",
    "\n",
    "# # generate some random data (approximately over 5 years)\n",
    "# data_1 = df[['Enquiry Status','Day']]\n",
    "# data_2 = df[['Enquiry Status','Hour']]\n",
    "\n",
    "# plot_date = data_1.groupby(['Day', 'Enquiry Status']).size().reset_index(name=\"counts\")\n",
    "# plot_date = plot_date.loc[plot_date['Enquiry Status'] == 'Accepted']\n",
    "\n",
    "# plot_time = data_2.groupby(['Hour', 'Enquiry Status']).size().reset_index(name=\"counts\")\n",
    "# plot_time = plot_time.loc[plot_time['Enquiry Status'] == 'Accepted']\n",
    "\n",
    "# plt.xlabel('Accpetances by hour')\n",
    "# plt.ylabel('Acceptances')\n",
    "# plt.plot(plot_time['Hour'], plot_time['counts'])\n",
    "\n",
    "# plt.title('Accpeted counts by Hour')\n",
    "# plt.bar(range(plot_time['Hour'].shape[0]), plot_time['counts'])\n",
    "# plt.xticks(range(plot_time['Hour'].shape[0]),plot_time['Hour'].values)\n",
    "# # plt.xticks(rotation=90)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import calendar\n",
    "\n",
    "# plt_accepted = df.loc[df['Enquiry Status'] == 'Accepted']\n",
    "\n",
    "# # get and sort acceptances by day\n",
    "# count_day_accepted = plt_accepted.groupby(['Weekday']).size().reset_index(name=\"counts\")\n",
    "# weekdays = list(calendar.day_name)\n",
    "# mapping = {day: i for i, day in enumerate(weekdays)}\n",
    "# key = count_day_accepted['Weekday'].map(mapping)\n",
    "# count_day_accepted = count_day_accepted.iloc[key.argsort()].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# plt_rejected = df.loc[df['Enquiry Status'] == 'Rejected']\n",
    "\n",
    "# count_day_rejected = plt_rejected.groupby(['Weekday']).size().reset_index(name=\"counts\")\n",
    "# weekdays = list(calendar.day_name)\n",
    "# mapping = {day: i for i, day in enumerate(weekdays)}\n",
    "# key = count_day_rejected['Weekday'].map(mapping)\n",
    "# count_day_rejected = count_day_rejected.iloc[key.argsort()].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# plt_X1 = plt_accepted[['Loan Amount','Weekday']]\n",
    "# plt_y1 = plt_accepted[['Enquiry Status']]\n",
    "\n",
    "# # ax = count_day.plot()\n",
    "# # ax.set_xlabel(\"Day\")\n",
    "# # plt.plot_date(x=count_day['day_of_week'], y=count_day['counts'],fmt=\"r-\")\n",
    "# # plt.plot_date(x=count_date['Enquired Date'], y=count_date['counts'],fmt=\"r-\")\n",
    "\n",
    "# # plt.plot(count_day_accepted['day_of_week'], count_day_accepted['counts'])\n",
    "# # plt.xticks(rotation=45)\n",
    "# # plt.show()\n",
    "\n",
    "# # print(count_day_accepted['day_of_week'].shape[0])\n",
    "# plt.title('Accpeted counts by day')\n",
    "# plt.bar(range(count_day_accepted['Weekday'].shape[0]), count_day_accepted['counts'])\n",
    "# plt.xticks(range(count_day_accepted['Weekday'].shape[0]),count_day_accepted['Weekday'].values, rotation=45)\n",
    "# plt.show()\n",
    "\n",
    "# plt.title('Rejected counts by day')\n",
    "# plt.bar(range(count_day_rejected['Weekday'].shape[0]), count_day_rejected['counts'])\n",
    "# plt.xticks(range(count_day_rejected['Weekday'].shape[0]),count_day_rejected['Weekday'].values, rotation=45)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self, columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self, X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = le.fit_transform(output[col])\n",
    "#                 output[col] = OneHotEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname, col in output.iteritems():\n",
    "                output[colname] = le.fit_transform(col)\n",
    "#                 output[colname] = OneHotEncoder().fit_transform(col)\n",
    "        return output\n",
    "       \n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"List of data types: \\n{}\".format(df.dtypes))\n",
    "\n",
    "# encoded_columns = list(df.select_dtypes(include=['category','object']))\n",
    "\n",
    "# print(\"selected encoded_columns: \\n{}\".format(encoded_columns))\n",
    "\n",
    "# df = MultiColumnLabelEncoder(columns = encoded_columns).fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.pairplot(df, hue=\"Enquiry Status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame.hist(df, figsize = [15,15]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = df[['Marketing Code','App Source', 'Web Source', 'Classification','Enquired Date',]]\n",
    "X = df[df.keys()]\n",
    "X = df.loc[:,df.columns != target]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Keys of enquiries_dataset: \\n{}\".format(X.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X: {}\".format(X.shape))\n",
    "print(\"Shape of y: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature selection\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "selected_X = model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                     test_size=0.3,\n",
    "                     random_state=0,\n",
    "                     stratify=y)\n",
    "# rescale data\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', C=0.1)\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "print('Training accuracy:', lr.score(X_train_std, y_train))\n",
    "print('Test accuracy:', lr.score(X_test_std, y_test))\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'cyan','magenta', 'yellow', 'black','pink', 'lightgreen', 'lightblue',\n",
    "          'gray', 'indigo', 'orange']\n",
    "\n",
    "weights, params = [], []\n",
    "for c in np.arange(-4., 6.):\n",
    "    lr = LogisticRegression(penalty='l1', C=10. ** c, random_state=0)\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    weights.append(lr.coef_[0])\n",
    "    params.append(10 ** c)\n",
    "    \n",
    "weights = np.array(weights)\n",
    "\n",
    "for column, color in zip(range(weights.shape[1]), colors):\n",
    "    plt.plot(params, weights[:, column],\n",
    "             label=X.columns[column],\n",
    "             color=color)\n",
    "    \n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=3)\n",
    "plt.xlim([10**(-5), 10**5])\n",
    "plt.ylabel('weight coefficient')\n",
    "plt.xlabel('C')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper left')\n",
    "ax.legend(loc='upper center',\n",
    "          bbox_to_anchor=(1.38, 1.03),\n",
    "          ncol=1, fancybox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train_std, y_train)\n",
    "pred_kn = knn.predict(X_test)\n",
    "print(\"Test score: {:.2f}\".format(knn.score(X_test_std, y_test)))\n",
    "\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# try n_neighbors from 1 to 10.\n",
    "neighbors_settings = range(1, 11)\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the model\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # record training set accuracy\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "    \n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "sgd.fit(X_train_std, y_train)\n",
    "pred_sgd = sgd.predict(X_test)\n",
    "print(\"Test score: {:.2f}\".format(sgd.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svc = svm.SVC(probability=True)\n",
    "svc.fit(X_train, y_train)\n",
    "pred_svc = svc.predict(X_test)\n",
    "print(\"Test score: {:.2f}\".format(svc.score(X_test, y_test)))\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# N = range(1, 16)\n",
    "# for n in N:\n",
    "#     pca = KernelPCA(n_components=n)\n",
    "#     X_n_kept = pca.fit_transform(X_test_std)\n",
    "#     # Estimate accuracy on the data set with top n components\n",
    "#     classifier = svm.SVC(gamma=0.001)\n",
    "#     score_n_components = cross_val_score(classifier, X_n_kept, y_test).mean()\n",
    "#     print('Score with the data set of top {0} components: {1:.2f}'.format(n, score_n_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10,\n",
    "                            random_state=1)\n",
    "rfc.fit(X_train_std, y_train)\n",
    "pred_forest = rfc.predict(X_test)\n",
    "\n",
    "print(\"Test score: {:.2f}\".format(rfc.score(X_test_std, y_test)))\n",
    "\n",
    "scores = cross_val_score(rfc, X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr = lr.fit(X_train_std, y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "\n",
    "# print(\"X_test_std {}\".format(X_test_std.shape))\n",
    "# N = range(1, 16)\n",
    "# for n in N:\n",
    "#     pca = KernelPCA(n_components=n)\n",
    "#     X_n_kept = pca.fit_transform(X_test_std)\n",
    "#     print(\"X_n_kept {}\".format(X_n_kept.shape))\n",
    "#     # Estimate accuracy on the data set with top n components\n",
    "#     classifier = LogisticRegression()\n",
    "#     score_n_components = cross_val_score(classifier, X_n_kept, y_test).mean()\n",
    "#     print('Score with the data set of top {0} components: {1:.2f}'.format(n, score_n_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.decomposition import KernelPCA\n",
    "\n",
    "# N = range(1, 16)\n",
    "# for n in N:\n",
    "#     pca = KernelPCA(n_components=n)\n",
    "#     X_n_kept = pca.fit_transform(y_test)\n",
    "#     print(\"X_n_kept {}\".format(X_n_kept.shape))\n",
    "#     # Estimate accuracy on the data set with top n components\n",
    "#     classifier = RandomForestClassifier()\n",
    "#     score_n_components = cross_val_score(classifier, X_n_kept, y_test).mean()\n",
    "#     print('Score with the data set of top {0} components: {1:.2f}'.format(n, score_n_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_labels = X.columns[:]\n",
    "importances = rfc.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, feat_labels[indices[f]], importances[indices[f]]))\n",
    "    \n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(X_train.shape[1]),importances[indices],align='center')\n",
    "plt.xticks(range(X_train.shape[1]),feat_labels[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from matplotlib.ticker import FuncFormatter\n",
    "# def millions(x, pos):\n",
    "#     'The two args are the value and tick position'\n",
    "#     return '$%1.1fM' % (x*1e-6)\n",
    "\n",
    "# formatter = FuncFormatter(millions)\n",
    "\n",
    "# count_amount_accepted = plt_accepted.groupby(['Loan Amount']).size().reset_index(name=\"counts\")\n",
    "# count_amount_rejected = plt_rejected.groupby(['Loan Amount']).size().reset_index(name=\"counts\")\n",
    "\n",
    "# # count_amount_accepted.to_csv('test.csv')\n",
    "# # display(count_amount_accepted)\n",
    "# fig, ax = plt.subplots()\n",
    "# plt.plot(count_amount_accepted['Loan Amount'], count_amount_accepted['counts'])\n",
    "# plt.xticks(rotation=45)\n",
    "# ax.xaxis.set_major_formatter(formatter)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "scores = cross_validation.cross_val_score(lr, X, y, cv=5)\n",
    "print(\"LogisticRegression cross_validation: {:.2f}\".format(np.mean(scores, axis=0)))\n",
    "\n",
    "scores = cross_validation.cross_val_score(knn, X, y, cv=5)\n",
    "print(\"KNeighborsClassifier cross_validation: {:.2f}\".format(np.mean(scores, axis=0)))\n",
    "\n",
    "scores = cross_validation.cross_val_score(sgd, X, y, cv=5)\n",
    "print(\"SGDClassifier cross_validation: {:.2f}\".format(np.mean(scores, axis=0)))\n",
    "\n",
    "scores = cross_validation.cross_val_score(svc, X, y, cv=5)\n",
    "print(\"SVC cross_validation: {:.2f}\".format(np.mean(scores, axis=0)))\n",
    "\n",
    "scores = cross_validation.cross_val_score(rfc, X, y, cv=5)\n",
    "print(\"RandomForestClassifier cross_validation: {:.2f}\".format(np.mean(scores, axis=0)))\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"LogisticRegression\")\n",
    "print(classification_report(y_test, pred_lr))\n",
    "\n",
    "print(\"KNeighborsClassifier\")\n",
    "print(classification_report(y_test, pred_kn))\n",
    "\n",
    "print(\"SGDClassifier\")\n",
    "print(classification_report(y_test, pred_sgd))\n",
    "\n",
    "print(\"SVC\")\n",
    "print(classification_report(y_test, pred_svc))\n",
    "\n",
    "print(\"RandomForestClassifier\")\n",
    "print(classification_report(y_test, pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "probs = rfc.predict_proba(X_test_std)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.title('Random Forest Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "probs = svc.predict_proba(X_test_std)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.title('SVC Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input_x = X.iloc[:]\n",
    "# input_x_test = X.iloc[:,idxs_selected]\n",
    "# # input_x = input_x.iloc[0,idxs_selected]\n",
    "\n",
    "# # input_x = input_x.drop('Enquiry Status', 1)\n",
    "\n",
    "# input_x_test = MultiColumnLabelEncoder(columns = input_x_test.keys()).fit_transform(input_x_test)\n",
    "# input_x_test = scaler.fit_transform(input_x_test)\n",
    "\n",
    "# # for row in input_x:\n",
    "# #     result = rfc.predict(row)[0]\n",
    "# #     proba = np.max(rfc.predict_proba(row))    \n",
    "\n",
    "# #     print('reuslt: {}'.format(le.inverse_transform(result)))\n",
    "# #     print('probability: {0}%'.format(proba))\n",
    "# #     print()\n",
    "\n",
    "# # result = rfc.predict(input_x)[0]\n",
    "# # proba = np.max(rfc.predict_proba(input_x))    \n",
    "\n",
    "# # print('reuslt: {}'.format(le.inverse_transform(result)))\n",
    "# # print('probability: {0}%'.format(proba))\n",
    "# result = rfc.predict(input_x_test)\n",
    "# result = le.inverse_transform(result)\n",
    "# proba = rfc.predict_proba(input_x_test)   \n",
    "# proba = [np.max(p) for p in proba]\n",
    "# input_x.to_csv('example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input_x = input_x.assign(predict=result.tolist())\n",
    "# input_x = input_x.assign(possibility=proba)\n",
    "# input_x.head()\n",
    "# input_x.to_csv('result/v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = '[{\"col 1\":\"a\",\"col 2\":\"b\"},{\"col 1\":\"c\",\"col 2\":\"d\"}]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.read_json(a, orient='records')\n",
    "# import json\n",
    "# test_json = json.dumps(a)\n",
    "test = pd.read_json(a, orient='records')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
