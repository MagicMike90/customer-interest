{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "from IPython.display import display\n",
    "\n",
    "# read whole year data\n",
    "allFiles = glob.glob(\"data/*.csv\")\n",
    "df = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "df = pd.concat(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['Marketing Code','App Source', 'Web Source', 'Classification','Enquired',\n",
    "                     'Loan Amount']\n",
    "target = 'Enquiry Status';\n",
    "whole_set = selected_features + [target]\n",
    "\n",
    "df = df[whole_set]\n",
    "df = df.replace('On Hold','Rejected')\n",
    "# convert loan amount to number type, and change string to NaN\n",
    "df['Loan Amount'] = pd.to_numeric(df['Loan Amount'],errors='coerce')\n",
    "df = df.dropna(axis=0, how='any')\n",
    "\n",
    "df['Loan Amount'] = df['Loan Amount'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data frame: (47403, 7)\n",
      "Keys of enquiries_dataset: \n",
      "Index(['Marketing Code', 'App Source', 'Web Source', 'Classification',\n",
      "       'Enquired', 'Loan Amount', 'Enquiry Status'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of data frame: {}\".format(df.shape))\n",
    "print(\"Keys of enquiries_dataset: \\n{}\".format(df.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of data types: \n",
      "Marketing Code    object\n",
      "App Source        object\n",
      "Web Source        object\n",
      "Classification    object\n",
      "Enquired          object\n",
      "Loan Amount        int64\n",
      "Enquiry Status    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"List of data types: \\n{}\".format(df.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'Enquiry Status']\n",
    "y = df['Enquiry Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# pipe_lr = make_pipeline(StandardScaler(),PCA(n_components=2),LogisticRegression(random_state=1))\n",
    "# pipe_lr.fit(X_train, y_train)\n",
    "# y_pred = pipe_lr.predict(X_test)\n",
    "# print('Test Accuracy: %.3f' % pipe_lr.score(X_test, y_test))\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col].astype(str))\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# feature selection\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "le = LabelEncoder()\n",
    "# Categorial feature ecoding\n",
    "X = MultiColumnLabelEncoder(columns = X.keys()).fit_transform(X)\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "\n",
    "# Get idxs of columns to keep\n",
    "idxs_selected = model.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mluo/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(),PCA(n_components=2),LogisticRegression(random_state=1))\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred = pipe_lr.predict(X_test)\n",
    "print('Test Accuracy: %.3f' % pipe_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mluo/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# rescale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=500,random_state=1)\n",
    "rfc.fit(X_train_scaled, y_train)\n",
    "pred_forest = rfc.predict(X_test)\n",
    "\n",
    "print(\"Test score: {:.2f}\".format(rfc.score(X_test_scaled, y_test)))\n",
    "\n",
    "scores = cross_val_score(rfc, X_test_scaled, y_test)\n",
    "print(\"Cross-validation scores: {}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_labels = X.columns[0:]\n",
    "importances = rfc.feature_importances_\n",
    "\n",
    "# reverse the list\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30,feat_labels[indices[f]],importances[indices[f]]))\n",
    "    \n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(X_train.shape[1]),importances[indices],align='center')\n",
    "plt.xticks(range(X_train.shape[1]),feat_labels[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_x = df.iloc[:]\n",
    "input_x_test = df.iloc[:,idxs_selected]\n",
    "\n",
    "input_x_test = MultiColumnLabelEncoder(columns = input_x_test.keys()).fit_transform(input_x_test)\n",
    "input_x_test = scaler.fit_transform(input_x_test)\n",
    "\n",
    "result = rfc.predict(input_x_test)\n",
    "result = le.inverse_transform(result)\n",
    "proba = rfc.predict_proba(input_x_test)   \n",
    "proba = [np.max(p) for p in proba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_x = input_x.assign(predict=result.tolist())\n",
    "input_x = input_x.assign(possibility=proba)\n",
    "input_x.to_csv('example_pipeline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
